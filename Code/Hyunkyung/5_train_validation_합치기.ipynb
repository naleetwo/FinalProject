{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c1c82c",
   "metadata": {},
   "source": [
    "# shuffle 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0114b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2a977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 23502/23502 [00:06<00:00, 3449.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0000_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0000_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0001_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0001_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0002_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23497</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_8_a0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23498</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_8_a0006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_8_a0007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23500</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_8_a0008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23501</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_8_a0009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23502 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename class\n",
       "0        V006_77_0_00_11_03_12_0_c01_20201013_0000_S01     0\n",
       "1      V006_77_0_00_11_03_12_0_c01_20201013_0000_S01_1     0\n",
       "2        V006_77_0_00_11_03_12_0_c01_20201013_0001_S01     0\n",
       "3      V006_77_0_00_11_03_12_0_c01_20201013_0001_S01_1     0\n",
       "4        V006_77_0_00_11_03_12_0_c01_20201013_0002_S01     0\n",
       "...                                                ...   ...\n",
       "23497   V006_77_1_19_11_03_12_3_9357q_20201130_8_a0005     3\n",
       "23498   V006_77_1_19_11_03_12_3_9357q_20201130_8_a0006     3\n",
       "23499   V006_77_1_19_11_03_12_3_9357q_20201130_8_a0007     3\n",
       "23500   V006_77_1_19_11_03_12_3_9357q_20201130_8_a0008     3\n",
       "23501   V006_77_1_19_11_03_12_3_9357q_20201130_8_a0009     3\n",
       "\n",
       "[23502 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 디렉토리 경로\n",
    "directory = r\"D:\\rawdata_disease_resize\\house\\train\\labels\"\n",
    "\n",
    "# 데이터프레임을 저장할 리스트\n",
    "data_list = []\n",
    "\n",
    "# 디렉토리 내의 파일들에 대해 반복\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            # 파일의 첫 번째 값 읽어오기\n",
    "            class_label = file.readline().split()[0]\n",
    "\n",
    "            # .txt 앞 문자열 추출\n",
    "            txt_prefix = os.path.splitext(filename)[0]\n",
    "            \n",
    "            # 데이터프레임에 추가\n",
    "            data_list.append([txt_prefix, class_label])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_train = pd.DataFrame(data_list, columns=[\"filename\", \"class\"])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff94a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4698/4698 [00:01<00:00, 3151.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c22_20201130_0001_S01_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c04_20201223_0000_S01_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c05_20201222_0000_S01_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c05_20201222_0001_S01_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c05_20201222_0002_S01_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4693</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4698 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename class\n",
       "0     V006_77_0_00_11_03_12_0_c22_20201130_0001_S01_2     0\n",
       "1     V006_77_0_00_11_03_13_0_c04_20201223_0000_S01_2     0\n",
       "2     V006_77_0_00_11_03_13_0_c05_20201222_0000_S01_2     0\n",
       "3     V006_77_0_00_11_03_13_0_c05_20201222_0001_S01_2     0\n",
       "4     V006_77_0_00_11_03_13_0_c05_20201222_0002_S01_2     0\n",
       "...                                               ...   ...\n",
       "4693   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0005     3\n",
       "4694   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0006     3\n",
       "4695   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0007     3\n",
       "4696   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0008     3\n",
       "4697   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0009     3\n",
       "\n",
       "[4698 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 디렉토리 경로\n",
    "directory = r\"D:\\rawdata_disease_resize\\house\\validation\\labels\"\n",
    "\n",
    "# 데이터프레임을 저장할 리스트\n",
    "data_list = []\n",
    "\n",
    "# 디렉토리 내의 파일들에 대해 반복\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            # 파일의 첫 번째 값 읽어오기\n",
    "            class_label = file.readline().split()[0]\n",
    "\n",
    "            # .txt 앞 문자열 추출\n",
    "            txt_prefix = os.path.splitext(filename)[0]\n",
    "            \n",
    "            # 데이터프레임에 추가\n",
    "            data_list.append([txt_prefix, class_label])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_val = pd.DataFrame(data_list, columns=[\"filename\", \"class\"])\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2293060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0000_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0000_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0001_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0001_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V006_77_0_00_11_03_12_0_c01_20201013_0002_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28195</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28196</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28197</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28198</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28199</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_9357q_20201130_9_a0009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename class\n",
       "0        V006_77_0_00_11_03_12_0_c01_20201013_0000_S01     0\n",
       "1      V006_77_0_00_11_03_12_0_c01_20201013_0000_S01_1     0\n",
       "2        V006_77_0_00_11_03_12_0_c01_20201013_0001_S01     0\n",
       "3      V006_77_0_00_11_03_12_0_c01_20201013_0001_S01_1     0\n",
       "4        V006_77_0_00_11_03_12_0_c01_20201013_0002_S01     0\n",
       "...                                                ...   ...\n",
       "28195   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0005     3\n",
       "28196   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0006     3\n",
       "28197   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0007     3\n",
       "28198   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0008     3\n",
       "28199   V006_77_1_19_11_03_12_3_9357q_20201130_9_a0009     3\n",
       "\n",
       "[28200 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_val], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 클래스별 인덱스 가져오기\n",
    "class_indices = {}\n",
    "for class_label in df['class'].unique():\n",
    "    indices = df[df['class'] == class_label].index.tolist()  # 인덱스를 리스트로 변환\n",
    "    class_indices[class_label] = indices\n",
    "\n",
    "# 클래스별 인덱스를 섞은 후 비율에 맞게 분할\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "for class_label, indices in class_indices.items():\n",
    "    np.random.shuffle(indices)  # 클래스별 인덱스 섞기\n",
    "\n",
    "    num_samples = len(indices)\n",
    "    num_train = int(num_samples * 0.8)  # train 비율\n",
    "    num_val = int(num_samples * 0.1)  # validation 비율\n",
    "    num_test = num_samples - num_train - num_val\n",
    "\n",
    "    train_indices.extend(indices[:num_train])\n",
    "    val_indices.extend(indices[num_train:num_train+num_val])\n",
    "    test_indices.extend(indices[num_train+num_val:])\n",
    "    \n",
    "# 데이터프레임을 train, validation, test로 분할\n",
    "train_df = df.loc[train_indices]\n",
    "val_df = df.loc[val_indices]\n",
    "test_df = df.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4990f31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10128\n",
       "0     5088\n",
       "1     4752\n",
       "3     2592\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc2d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1266\n",
       "0     636\n",
       "1     594\n",
       "3     324\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23a42b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1266\n",
       "0     636\n",
       "1     594\n",
       "3     324\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b435f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv')\n",
    "val_df.to_csv('val_df.csv')\n",
    "test_df.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87fe3f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c07_20201202_0314_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c06_20201209_0074_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c01_20201013_0005_S01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c04_20201222_0034_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25228</th>\n",
       "      <td>V006_77_0_00_11_03_13_0_c19_20201222_0006_S01_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22318</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_2851q_20201210_3_a0006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22613</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_4396b_20201210_3_a0001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23012</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_7711b_20201118_30_a0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12511</th>\n",
       "      <td>V006_77_1_18_11_03_13_3_8419w_20201016_233_a0009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22261</th>\n",
       "      <td>V006_77_1_19_11_03_12_3_2851q_20201210_30_a0009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename class\n",
       "2562    V006_77_0_00_11_03_13_0_c07_20201202_0314_S01_1     0\n",
       "1812    V006_77_0_00_11_03_13_0_c06_20201209_0074_S01_1     0\n",
       "1044      V006_77_0_00_11_03_13_0_c01_20201013_0005_S01     0\n",
       "1214    V006_77_0_00_11_03_13_0_c04_20201222_0034_S01_1     0\n",
       "25228   V006_77_0_00_11_03_13_0_c19_20201222_0006_S01_1     0\n",
       "...                                                 ...   ...\n",
       "22318    V006_77_1_19_11_03_12_3_2851q_20201210_3_a0006     3\n",
       "22613    V006_77_1_19_11_03_12_3_4396b_20201210_3_a0001     3\n",
       "23012   V006_77_1_19_11_03_12_3_7711b_20201118_30_a0000     3\n",
       "12511  V006_77_1_18_11_03_13_3_8419w_20201016_233_a0009     3\n",
       "22261   V006_77_1_19_11_03_12_3_2851q_20201210_30_a0009     3\n",
       "\n",
       "[22560 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549658d",
   "metadata": {},
   "source": [
    "- train_df -> images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "046e8813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3771\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/train/images\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/train/images\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccbb46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22560it [10:03, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/validation/images\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/train/images\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a8a7c",
   "metadata": {},
   "source": [
    "- train_df -> labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d0615c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22560it [32:27, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/train/labels\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/train/labels\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7285b672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22560it [06:40, 56.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/validation/labels\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/train/labels\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca6e91",
   "metadata": {},
   "source": [
    "- val_df -> images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d91ae20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [06:01,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/train/images\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/validation/images\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(val_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "419f71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [01:12, 38.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/validation/images\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/validation/images\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(val_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e10f0c",
   "metadata": {},
   "source": [
    "- val_df -> labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc91ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [03:29, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/train/labels\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/validation/labels\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(val_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f9d128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [00:46, 60.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/validation/labels\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/validation/labels\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(val_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea8dc4",
   "metadata": {},
   "source": [
    "- test_df -> images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3f5573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [05:54,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/train/images\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/test/images\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e26a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [01:08, 40.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/validation/images\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/test/images\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99640b",
   "metadata": {},
   "source": [
    "- test_df -> labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e5db13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [03:28, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/train/labels\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/test/labels\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cecdc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2820it [00:44, 63.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:/rawdata_disease_resize/house/validation/labels\"\n",
    "target_dir = \"D:/rawdata_disease_resize_shuffle/house/test/labels\"\n",
    "\n",
    "not_found = 0\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    source_files = glob.glob(os.path.join(source_dir, filename + \".*\"))  # 파일 확장자 앞 부분과 일치하는 파일들 선택\n",
    "    if len(source_files) > 0:\n",
    "        target_file = os.path.join(target_dir, os.path.basename(source_files[0]))  # 대상 디렉토리에 복사될 파일 경로\n",
    "        shutil.copy(source_files[0], target_file)\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62614892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
