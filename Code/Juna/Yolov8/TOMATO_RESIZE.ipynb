{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297825a5-a9d2-42cf-8199-329db3613572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea44cc8b-99cc-43e2-99a4-9b9faa85728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50384f-fb5a-45db-9d2c-b1d11787063f",
   "metadata": {},
   "source": [
    "#### 원본 /4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8581d42-53cf-4f62-94ec-1b01cbab68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# input_directory = \"C:/juna27/PythonWork/AI/data/tomato_yolo/train/images/\"\n",
    "\n",
    "# output_directory = \"C:/juna27/PythonWork/AI/data/tomato_yolo_resize/train/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661c7aab-d91f-41f3-9c02-8b33a7a5cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ㅁㅁㅁㅁㅁㅁㅁㅁㅁㅁㅁㅁㅁ\n",
    "\n",
    "input_directory = \"C:/juna27/PythonWork/AI/data/tomato_yolo_shuffle_2/test_test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164a996-2376-434b-9f8c-7d7088b2f21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de829a4a-7888-452a-b649-52a6227f663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 디렉토리 내의 모든 파일에 대해 반복\n",
    "for filename in os.listdir(input_directory):\n",
    "    # 파일의 전체 경로\n",
    "    input_image_path = os.path.join(input_directory, filename)\n",
    "    \n",
    "    # 이미지 읽어오기\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "\n",
    "    # 이미지의 너비, 폭 가져오기\n",
    "    width = input_image.shape[1]\n",
    "    height = input_image.shape[0]\n",
    "\n",
    "    # 이미지의 크기 조절\n",
    "    output_image = cv2.resize(input_image, dsize=(width // 4, height // 4))\n",
    "\n",
    "    # 복사된 이미지의 저장 경로\n",
    "    # output_image_path = os.path.join(output_directory, filename)\n",
    "\n",
    "    # 이미지 저장\n",
    "    # cv2.imwrite(output_image_path, output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75c93713-245b-4333-a8c2-cac820e2e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = input_image.shape[1]\n",
    "height = input_image.shape[0]\n",
    "\n",
    "output_image = cv2.resize(input_image, dsize=(width // 4, height // 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08dc559f-da10-4c81-9c38-1941f93ffa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "1008\n"
     ]
    }
   ],
   "source": [
    "print(width)\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e00b0eb-d1e8-4f60-b9d8-f4f6953e9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # val\n",
    "# input_directory = \"C:/juna27/PythonWork/AI/data/tomato_yolo/val/images/\"\n",
    "\n",
    "# output_directory = \"C:/juna27/PythonWork/AI/data/tomato_yolo_resize/val/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b6b5e38-3250-4a7f-b0aa-cf26ae4c3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 입력 디렉토리 내의 모든 파일에 대해 반복\n",
    "# for filename in os.listdir(input_directory):\n",
    "#     # 파일의 전체 경로\n",
    "#     input_image_path = os.path.join(input_directory, filename)\n",
    "    \n",
    "#     # 이미지 읽어오기\n",
    "#     input_image = cv2.imread(input_image_path)\n",
    "\n",
    "#     # 이미지의 너비, 폭 가져오기\n",
    "#     width = input_image.shape[1]\n",
    "#     height = input_image.shape[0]\n",
    "\n",
    "#     # 이미지의 크기 조절\n",
    "#     output_image = cv2.resize(input_image, dsize=(width // 4, height // 4))\n",
    "\n",
    "#     # 복사된 이미지의 저장 경로\n",
    "#     output_image_path = os.path.join(output_directory, filename)\n",
    "\n",
    "#     # 이미지 저장\n",
    "#     cv2.imwrite(output_image_path, output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b8236-75e2-4095-9824-dd75a42f99ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841bf54-d4d6-48b5-a861-4e68e1795b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecb8ac6-8633-4e2b-bd66-e5063dd6f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib as mlp\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname = \"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "plt.rc(\"font\", family = font_name)\n",
    "mlp.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608746a-4384-4080-9e80-604c013c5efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c623b4f8-b261-4256-8057-5949a6dbaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b90f063-281f-4a9a-a571-6ab608c565ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.117  Python-3.9.13 torch-2.0.1+cpu CPU\n",
      "Setup complete  (8 CPUs, 15.9 GB RAM, 549.2/915.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a7c33e-8994-4dc4-9596-05b561dbf325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "# model = YOLO(\"yolov8s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb261b7-cbfa-4133-b39b-e171717adf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    \"train\" : \"train/images/\",\n",
    "    \"val\" : \"val/images/\",\n",
    "    \"test\" : \"test/images/\",\n",
    "    \"nc\" : 3,\n",
    "    \"names\": ['healthy', 'Leaf mold', 'TYLCV']\n",
    "}\n",
    "\n",
    "with open(\"data/tomato_yolo_resize/tom_out_leaf.yaml\", \"w\") as f:\n",
    "    yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f85986-c190-40df-a36f-7e897d1edffb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training : 2023-06-29 20:27:00.940395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.124 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.117  Python-3.9.13 torch-2.0.1+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml, epochs=6, patience=4, batch=32, imgsz=614, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "WARNING  imgsz=[614] must be multiple of max stride 32, updating to [640]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\train\\labels.cache... 25446 images, 0 backgrounds, 0 co\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\val\\labels.cache... 4934 images, 0 backgrounds, 0 corrupt\u001b[0m\n",
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 6 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/6         0G     0.9427      1.574      1.338         16        640: 100%|██████████| 796/796 [2:50:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [11:13\n",
      "                   all       4934       4934      0.796      0.794      0.823      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/6         0G     0.9405      1.018      1.317         15        640: 100%|██████████| 796/796 [2:50:16<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [11:13\n",
      "                   all       4934       4934      0.833      0.811      0.844      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/6         0G     0.9058      0.917      1.293         15        640: 100%|██████████| 796/796 [2:50:22<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [11:18\n",
      "                   all       4934       4934      0.761      0.797       0.83       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/6         0G     0.8571     0.8539      1.263         13        640: 100%|██████████| 796/796 [2:50:03<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [11:21\n",
      "                   all       4934       4934      0.835      0.831       0.88      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/6         0G     0.8346     0.8178      1.247         63        640:  51%|█████     | 403/796 [1:26:37<1:24:2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10872\\2494635026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m model.train(data=\"C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml\",\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             batch=32, imgsz=614)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[1;31m# attach optional HUB session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m         \u001b[1;31m# Update model and cfg after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[1;31m# Backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start Training :\", start_time)\n",
    "##########\n",
    "\n",
    "\n",
    "model.train(data=\"C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml\",\n",
    "            epochs=6, patience=4,\n",
    "            batch=32, imgsz=614)\n",
    "\n",
    "\n",
    "##########\n",
    "end_time = datetime.now()\n",
    "print(\"End of Training :\", end_time)\n",
    "print(\"\\nTime taken :\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0127013-51cf-436e-830f-0b5fc59b7695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a315931-a6ce-4daa-92bf-4cacf9446c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ce13ad4-7391-4e29-8c89-e3e03eb186bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\02a29ab9-8cba-47a0-bc2f-e7af7dbae149___Crnl_L.Mold 7165.JPG: 416x416 2 TYLCVs, 78.8ms\n",
      "image 2/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\075f199d61dd605509cd86bf8d373d44.jpg: 288x416 (no detections), 88.8ms\n",
      "image 3/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0a555f63-bf03-4958-8993-e1932b8dce9f___Crnl_L.Mold 9064.JPG: 416x416 1 Leaf mold, 41.9ms\n",
      "image 4/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0a9b3ff4-5343-4814-ac2c-fdb3613d4e4d___Crnl_L.Mold 6559.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 5/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ac36661-a47d-47ff-8948-42edec033b87___Crnl_L.Mold 9127.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 6/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0adab1d4-5696-4cd8-8453-3931b70e856d___Crnl_L.Mold 8689.JPG: 416x416 1 TYLCV, 53.9ms\n",
      "image 7/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ae36892-5cb1-476e-8a51-b7fd8183a535___Crnl_L.Mold 6728.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 8/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0b3d5bf2-607f-4f95-bdcd-3542b8bd3244___Crnl_L.Mold 6654.JPG: 416x416 1 Leaf mold, 1 TYLCV, 40.9ms\n",
      "image 9/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0b943ada-01a9-4ce0-a607-e799394856de___Crnl_L.Mold 7008.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 10/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ba88812-fa4f-4602-bcec-c03cd7d0ba2b___Crnl_L.Mold 6990.JPG: 416x416 1 Leaf mold, 51.9ms\n",
      "image 11/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0bae0514-799a-479f-a407-ad763f458916___Crnl_L.Mold 8989.JPG: 416x416 1 Leaf mold, 50.9ms\n",
      "image 12/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0bb34c9b-ecf7-4fb1-8ee1-098bccdcdaae___Crnl_L.Mold 6522.JPG: 416x416 1 Leaf mold, 44.9ms\n",
      "image 13/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0bc63b4c-e41b-4338-a8ac-af664048fdbb___Crnl_L.Mold 6913.JPG: 416x416 1 Leaf mold, 48.9ms\n",
      "image 14/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0bc8fe4f-f614-43ce-bb2f-e3c0ef79f148___Crnl_L.Mold 8907.JPG: 416x416 1 healthy, 45.9ms\n",
      "image 15/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0c0debed-e807-4236-a2e3-d9b72f54367f___Crnl_L.Mold 6899.JPG: 416x416 1 TYLCV, 48.9ms\n",
      "image 16/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ced0bae-d224-43f5-8fd7-072c7cbd8f77___Crnl_L.Mold 9161.JPG: 416x416 1 Leaf mold, 41.9ms\n",
      "image 17/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0d54c850-da9a-498d-a636-ddeac067fd7e___Crnl_L.Mold 6746.JPG: 416x416 1 Leaf mold, 43.9ms\n",
      "image 18/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0db4cbf4-fa94-42c8-8bf5-90114281c569___Crnl_L.Mold 8681.JPG: 416x416 1 Leaf mold, 1 TYLCV, 48.9ms\n",
      "image 19/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ddf82ad-9004-4913-ac9c-d00333d7c858___Crnl_L.Mold 7089.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 20/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0de02a32-f166-4d67-bbb8-689e96d04c44___Crnl_L.Mold 8811.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 21/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0e508a3f-af06-4c8a-be78-5c38d2d4fb68___Crnl_L.Mold 6775.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 22/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0e5b669e-8534-45ab-a3c0-63134e685069___Crnl_L.Mold 7144.JPG: 416x416 1 TYLCV, 47.9ms\n",
      "image 23/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ed11606-167f-4951-9a07-ffaa7e2aa88a___Crnl_L.Mold 6831.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 24/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0eda4dc5-7f7b-4e27-9e53-1e0326eef88e___Crnl_L.Mold 8850.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 25/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0ee63bfa-d01f-4adb-b954-924f271a4d4f___Crnl_L.Mold 9022.JPG: 416x416 1 Leaf mold, 50.9ms\n",
      "image 26/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0f1ce7cf-da72-4ddb-9bdb-a1af620537c6___Crnl_L.Mold 6840.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 27/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0f740b31-f63b-4193-ab1a-6795c11a7f00___Crnl_L.Mold 7033.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 28/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\0fd01669-64ab-4042-9715-bf1bcb2ccfbf___Crnl_L.Mold 6996.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 29/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1a1acd8f-bd8d-47be-945d-ce308dffd678___Crnl_L.Mold 6675.JPG: 416x416 1 Leaf mold, 41.9ms\n",
      "image 30/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1af07f2b-027b-4792-80c5-2c20a4ed538c___YLCV_NREC 0179.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 31/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1af287e6-9d1e-4501-a113-d1a2b7c54b62___YLCV_GCREC 5321.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 32/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1af87bdf-0bd0-4146-93e5-cc5f97d98b05___UF.GRC_YLCV_Lab 01968.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 33/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1afbcb6f-91b5-444d-a383-2f32223b6bf0___YLCV_GCREC 2184.JPG: 416x416 (no detections), 41.9ms\n",
      "image 34/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b02f13d-08c6-4f7b-b0ae-2bc026a92759___YLCV_NREC 2961.JPG: 416x416 1 TYLCV, 47.9ms\n",
      "image 35/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b13e94c-da43-4bf4-9e31-d3740505b8c1___YLCV_GCREC 2662.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 36/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b1762b5-7aef-463c-ab99-bcc49246407a___UF.GRC_YLCV_Lab 01470.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 37/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b273914-1083-497e-a4fb-4a515ea53296___UF.GRC_YLCV_Lab 08552.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 38/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b2db321-28cd-4e33-88eb-b6c1302ca033___Crnl_L.Mold 6701.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 39/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b2e12ce-3b2e-4747-85f8-de80a3d5dd35___UF.GRC_YLCV_Lab 08565.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 40/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b2e9df8-8584-4ec3-bdee-a24b054a3529___YLCV_GCREC 2127.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 41/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b35b99c-c7c0-4f2c-975e-148e4b6e18b3___Crnl_L.Mold 8820.JPG: 416x416 2 Leaf molds, 49.9ms\n",
      "image 42/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b4ded19-b85b-4916-a158-6d8203062996___YLCV_GCREC 2230.JPG: 416x416 (no detections), 50.9ms\n",
      "image 43/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b55735a-c10e-4ea9-969d-8fb3fac8622f___UF.GRC_YLCV_Lab 02818.JPG: 416x416 (no detections), 45.9ms\n",
      "image 44/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b561161-1e63-4de0-889a-9c7b13487e18___Crnl_L.Mold 6596.JPG: 416x416 1 Leaf mold, 45.9ms\n",
      "image 45/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b568289-2f14-4019-b028-3f02ffe3752b___YLCV_NREC 2254.JPG: 416x416 1 healthy, 44.9ms\n",
      "image 46/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b7cabad-63f8-4022-8133-e972c9600b56___YLCV_NREC 2726.JPG: 416x416 (no detections), 42.9ms\n",
      "image 47/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b80b934-9b73-4c3b-8306-8058b59e766b___YLCV_GCREC 2027.JPG: 416x416 (no detections), 42.9ms\n",
      "image 48/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b85c0b1-e76a-4bfb-9bb2-576103e7a5bb___UF.GRC_YLCV_Lab 01824.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 49/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b94c436-a664-4e2a-af62-8e4d3761754a___YLCV_GCREC 2343.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 50/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b951a13-a6af-48f7-8d4c-fbdf2d4d0c7c___UF.GRC_YLCV_Lab 02208.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 51/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b977d41-3763-42c6-9d9b-e791db254f7e___YLCV_NREC 2716.JPG: 416x416 1 Leaf mold, 44.9ms\n",
      "image 52/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b984071-0529-4e15-9157-0b4b4a214d8f___UF.GRC_YLCV_Lab 08574.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 53/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1b99da77-2a28-4ee4-8ef6-e86b78aa35aa___YLCV_NREC 0232.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 54/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ba3b050-8dfe-4ff9-aaa6-dff4f961e7ae___UF.GRC_YLCV_Lab 03009.JPG: 416x416 (no detections), 57.9ms\n",
      "image 55/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bc2555a-b8c3-4be6-9ce2-f52573f6eea0___UF.GRC_YLCV_Lab 09562.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 56/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1be94ab9-681b-4cbb-9304-e4f4178a74e9___UF.GRC_YLCV_Lab 02822.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 57/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bea01a0-c680-4f6b-9b59-56386acb2d7d___YLCV_NREC 2796.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 58/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bef6514-c4be-4417-a390-3c506d4f1404___UF.GRC_YLCV_Lab 02020.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 59/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bf681a8-33b3-4c87-849a-ba4247bd6b54___YLCV_NREC 0093.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 60/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bf89324-315f-4267-9009-fe116526a0b5___UF.GRC_YLCV_Lab 02379.JPG: 416x416 (no detections), 57.8ms\n",
      "image 61/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bfa27f7-fdca-4991-9d93-361e45b52304___UF.GRC_YLCV_Lab 02071.JPG: 416x416 1 healthy, 45.9ms\n",
      "image 62/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bfe7244-44ab-4fac-abe5-f229217cdf0b___Crnl_L.Mold 6815.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 63/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1bff0039-09f4-4616-8c63-52021eef2533___YLCV_GCREC 2091.JPG: 416x416 1 healthy, 1 TYLCV, 45.9ms\n",
      "image 64/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c03ffcb-9476-453c-96be-5bd1f629b2d1___Crnl_L.Mold 8853.JPG: 416x416 1 Leaf mold, 49.9ms\n",
      "image 65/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c0478dc-09a0-4828-ab05-60c7063c7491___UF.GRC_YLCV_Lab 03153.JPG: 416x416 (no detections), 41.9ms\n",
      "image 66/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c1e1887-c9f8-4498-8ed5-4b09931946e0___UF.GRC_YLCV_Lab 03400.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 67/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c1f329f-d726-463f-8e54-a5ed2e7c9e87___UF.GRC_YLCV_Lab 03254.JPG: 416x416 (no detections), 44.9ms\n",
      "image 68/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c228970-4090-4dff-8f24-5d923e965e13___YLCV_GCREC 2430.JPG: 416x416 1 Leaf mold, 44.9ms\n",
      "image 69/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c264e0f-1988-4d30-a311-7422148656f8___YLCV_GCREC 2789.JPG: 416x416 1 Leaf mold, 43.9ms\n",
      "image 70/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c28ac78-ae5c-4e33-81bb-c2311ded2d8d___YLCV_GCREC 2560.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 71/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c3779b9-cb13-43b0-9a4a-01f96e7d039f___YLCV_GCREC 2545.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 72/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c5303b5-2951-40f6-8e82-bf2ae4d666f2___YLCV_NREC 2013.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 73/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c5a96dd-01aa-4481-83a9-5c6f650ab2b5___UF.GRC_YLCV_Lab 08543.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 74/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c70bf65-e808-49de-bea2-7e47ef01c139___UF.GRC_YLCV_Lab 02768.JPG: 416x416 1 TYLCV, 39.9ms\n",
      "image 75/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c8981d8-e6f5-4b26-b1ed-b0dea1a622d1___YLCV_NREC 2240.JPG: 416x416 1 TYLCV, 47.9ms\n",
      "image 76/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c915a75-66fa-439a-8772-8c794e2cc19b___YLCV_GCREC 2861.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 77/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1c9968b7-d736-4101-865a-4d77053d4e94___YLCV_NREC 2643.JPG: 416x416 (no detections), 40.9ms\n",
      "image 78/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ca6f94a-9f5b-471c-8c72-58fab83514c7___UF.GRC_YLCV_Lab 01453.JPG: 416x416 1 healthy, 1 TYLCV, 43.9ms\n",
      "image 79/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1caa682c-2a12-483d-96a3-a9548428fb27___YLCV_GCREC 5497.JPG: 416x416 (no detections), 39.9ms\n",
      "image 80/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1caefc52-d9d0-4493-8f35-4c366a041d93___YLCV_NREC 2803.JPG: 416x416 (no detections), 40.9ms\n",
      "image 81/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cba0a0a-1e54-4ce9-b88c-722a6e8e12b7___YLCV_GCREC 2409.JPG: 416x416 1 TYLCV, 53.9ms\n",
      "image 82/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cc29336-a8cb-466f-a585-997f2cf8f2a3___UF.GRC_YLCV_Lab 01632.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 83/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cc5fa35-fde4-4b2d-b543-f0b7e6f5eb79___UF.GRC_YLCV_Lab 02152.JPG: 416x416 1 healthy, 1 TYLCV, 49.9ms\n",
      "image 84/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cd0ab0b-f4cf-4f2f-960a-455de4cd4c1e___YLCV_GCREC 2897.JPG: 416x416 2 Leaf molds, 44.9ms\n",
      "image 85/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cd27c22-6bd1-479d-a548-4e7b953676c8___UF.GRC_YLCV_Lab 01373.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 86/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cda9dae-d9ec-42b2-a420-52001ccb4941___UF.GRC_YLCV_Lab 03302.JPG: 416x416 1 TYLCV, 48.9ms\n",
      "image 87/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1cf49b23-0a6d-44b7-9a02-c7870d48527c___UF.GRC_YLCV_Lab 01496.JPG: 416x416 1 healthy, 42.9ms\n",
      "image 88/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d1d75b8-9cf7-4df5-be43-47aedb745b6a___YLCV_GCREC 2000.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 89/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d1f8ce2-c216-45b0-910d-07382bd1d27a___UF.GRC_YLCV_Lab 01353.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 90/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d235cd7-c782-4e3a-9220-60a1e8eaa833___YLCV_NREC 2880.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 91/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d25cb12-499f-453f-9a62-dbc3fd20b220___Crnl_L.Mold 7061.JPG: 416x416 1 TYLCV, 38.9ms\n",
      "image 92/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d284bff-229f-4fb3-89c6-afdaff9e6f3e___UF.GRC_YLCV_Lab 08577.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 93/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d2c329f-db43-4e47-b3bc-93f84ec812cc___YLCV_NREC 2310.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 94/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d3441cd-0da1-4fc0-858a-e9687a104a10___UF.GRC_YLCV_Lab 09333.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 95/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d3807d1-263e-4818-ac13-416627479eb9___UF.GRC_YLCV_Lab 02241.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 96/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d389f4a-ac40-4233-8b73-5bbf4428fda2___UF.GRC_YLCV_Lab 01279.JPG: 416x416 1 TYLCV, 38.9ms\n",
      "image 97/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d4fd3e9-0b14-4eb4-8034-699cf0c4ca3e___YLCV_NREC 2583.JPG: 416x416 (no detections), 44.9ms\n",
      "image 98/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d5035e8-e116-4c36-a259-df87a69bc953___UF.GRC_YLCV_Lab 09586.JPG: 416x416 1 healthy, 57.8ms\n",
      "image 99/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d5d8433-3df8-4b82-9399-c139eaa3a8e6___YLCV_GCREC 1989.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 100/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d71aaf7-0c50-4668-818f-1481a1c367cd___YLCV_GCREC 2857.JPG: 416x416 (no detections), 41.9ms\n",
      "image 101/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d7ce115-b719-4236-948f-5640817b43c3___UF.GRC_YLCV_Lab 02829.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 102/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d8627f3-55b7-46c6-8cae-af9737f11f79___UF.GRC_YLCV_Lab 02472.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 103/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1d89e540-4dc1-442f-a5d8-b44bb5100bda___UF.GRC_YLCV_Lab 02480.JPG: 416x416 1 TYLCV, 57.8ms\n",
      "image 104/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1da120f6-8e0b-424a-b82a-cd1a73cec059___YLCV_GCREC 2643.JPG: 416x416 1 TYLCV, 59.8ms\n",
      "image 105/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1da2cd46-6067-4b47-a453-e02754962329___UF.GRC_YLCV_Lab 01728.JPG: 416x416 1 healthy, 44.9ms\n",
      "image 106/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1da4146e-31fa-4361-9ee9-dbd1545f85ec___UF.GRC_YLCV_Lab 02047.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 107/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1da5a1f0-7b30-4984-869e-ecc7a618eb29___YLCV_NREC 2840.JPG: 416x416 1 TYLCV, 50.9ms\n",
      "image 108/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1da736d4-1d24-47f8-9989-bfed656a7e9d___YLCV_NREC 1989.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 109/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1db26dba-d945-4ef1-9c64-dacfa10ce08a___UF.GRC_YLCV_Lab 02960.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 110/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1dc30471-999e-4b74-a775-c85fc2c7ab89___UF.GRC_YLCV_Lab 02134.JPG: 416x416 (no detections), 43.9ms\n",
      "image 111/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1dd0d62f-7ef7-477f-b781-83423446a1f5___UF.GRC_YLCV_Lab 01580.JPG: 416x416 (no detections), 45.9ms\n",
      "image 112/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1df0792a-e9eb-4eef-8e59-77ac4ed0a422___UF.GRC_YLCV_Lab 02641.JPG: 416x416 (no detections), 46.9ms\n",
      "image 113/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1df30f7b-fece-4855-b82d-4abe8351a4ef___YLCV_NREC 2591.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 114/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1df98389-aa45-4b67-b2da-38642fe8841b___UF.GRC_YLCV_Lab 02295.JPG: 416x416 (no detections), 49.9ms\n",
      "image 115/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1dfb7895-5477-4ad0-b02e-bbdfab409cf6___YLCV_NREC 0240.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 116/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1dfbb58c-b33a-4b2e-a5fa-5df40246e7e8___UF.GRC_YLCV_Lab 01421.JPG: 416x416 1 healthy, 41.9ms\n",
      "image 117/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1dfeecca-ba78-4d56-88fe-71b9410b8e7a___YLCV_NREC 0169.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 118/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e02db5d-5674-4bfe-ac90-64fb69abfad1___UF.GRC_YLCV_Lab 02989.JPG: 416x416 (no detections), 44.9ms\n",
      "image 119/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e23b687-67ac-466c-b14e-49f0fe717ac0___UF.GRC_YLCV_Lab 01647.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 120/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e3d3162-4650-4e88-8f42-b76360c44f9d___YLCV_NREC 2190.JPG: 416x416 (no detections), 41.9ms\n",
      "image 121/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e5d50b9-7cf6-4ea3-9e39-020e59c72130___UF.GRC_YLCV_Lab 03092.JPG: 416x416 1 TYLCV, 53.9ms\n",
      "image 122/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e619c8a-6752-4654-90b8-598397347530___UF.GRC_YLCV_Lab 02524.JPG: 416x416 1 Leaf mold, 40.9ms\n",
      "image 123/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e624f89-d4ae-421b-9e9f-dcccd20211ac___YLCV_GCREC 5437.JPG: 416x416 (no detections), 50.9ms\n",
      "image 124/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e832665-08e7-4d77-9ab0-39a5fe3c919a___UF.GRC_YLCV_Lab 02473.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 125/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e83510e-18e7-4c6d-9223-3450766715c8___UF.GRC_YLCV_Lab 01939.JPG: 416x416 (no detections), 40.9ms\n",
      "image 126/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e891a18-662b-41d6-9bf3-a50eb7f58fbe___YLCV_NREC 0231.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 127/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e903e25-34b2-4207-94ed-f862a632a88a___YLCV_NREC 2158.JPG: 416x416 1 TYLCV, 43.9ms\n",
      "image 128/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e924491-cb5f-4843-8f26-de597f552240___YLCV_NREC 2011.JPG: 416x416 (no detections), 45.9ms\n",
      "image 129/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1e95f4dc-6fa2-4fbb-a8b3-426e43f95d69___UF.GRC_YLCV_Lab 03118.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 130/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ea07778-c22f-4183-ba26-ed5dee8e1589___UF.GRC_YLCV_Lab 02666.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 131/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1eac2879-1201-4d11-8652-547787cff379___YLCV_GCREC 5357.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 132/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ead601d-c2c0-44a6-90cd-e20680ab559c___YLCV_GCREC 2612.JPG: 416x416 1 Leaf mold, 44.9ms\n",
      "image 133/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ed685c5-7ed4-497e-b9dc-f2851fe7d865___Crnl_L.Mold 6828.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 134/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ee4066c-c130-42e8-a95b-17453919f4fb___YLCV_GCREC 2202.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 135/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1ee40690-2367-4a13-92ae-32b308b9533f___YLCV_NREC 2548.JPG: 416x416 1 TYLCV, 50.9ms\n",
      "image 136/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1eeab195-9373-4dfc-b4f7-b3198c542b08___YLCV_NREC 2141.JPG: 416x416 1 Leaf mold, 46.9ms\n",
      "image 137/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1f5c3b37-5590-4db7-a702-0cd93db0c929___Crnl_L.Mold 6930.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 138/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1f64f046-46e6-47b3-91ef-31c2433face3___Crnl_L.Mold 9089.JPG: 416x416 1 Leaf mold, 46.9ms\n",
      "image 139/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1fa78650-4f81-4c8f-9190-91f1057d1158___Crnl_L.Mold 9083.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 140/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\1fef5c8b-7d83-45b5-9031-f636c3dc44ae___Crnl_L.Mold 8953.JPG: 416x416 1 Leaf mold, 45.9ms\n",
      "image 141/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2a15214d-cee6-4359-8baa-7281f3fc0182___Crnl_L.Mold 8672.JPG: 416x416 1 TYLCV, 45.9ms\n",
      "image 142/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2a27ed39-5f6c-490e-8dae-8b1df4683dbc___Crnl_L.Mold 9099.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 143/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2aa365ee-c396-47e3-bf04-aad9d18f470f___Crnl_L.Mold 6655.JPG: 416x416 2 Leaf molds, 44.9ms\n",
      "image 144/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2aa4f976-9ac1-496d-9b58-0ec03e4bbad8___Crnl_L.Mold 7067.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 145/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2b31c158-d7d5-4625-b13b-e3e626d791ff___Crnl_L.Mold 6665.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 146/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2b727376-492d-47dd-983a-c8f9c7ab386a___Crnl_L.Mold 6556.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 147/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2b8557bc-3b98-4169-826c-628c5a683d70___Crnl_L.Mold 6539.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 148/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2b8e612f-7448-44f7-899c-95b3c8291824___Crnl_L.Mold 6671.JPG: 416x416 1 healthy, 1 Leaf mold, 40.9ms\n",
      "image 149/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\2ba2d560-919c-48cd-8f98-c4caf8fc37e7___Crnl_L.Mold 8994.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 150/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\33973_14684_430.jpg: 320x416 (no detections), 70.8ms\n",
      "image 151/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\42c19174aed93affe4e0ce47d9e13bc3 (1).jpg: 384x416 (no detections), 241.4ms\n",
      "image 152/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\51ffb177-e606-4ef0-8061-3ff092fe55e9.jpg: 288x416 (no detections), 33.9ms\n",
      "image 153/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\59776_42276_4212.jpg: 288x416 (no detections), 32.9ms\n",
      "image 154/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\987780_265887_4943.jpg: 256x416 (no detections), 216.4ms\n",
      "image 155/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_02a29ab9-8cba-47a0-bc2f-e7af7dbae149___Crnl_L.Mold 7165.JPG_ad43287f-fcae-4718-a08c-b976a2e26d76.JPG: 416x416 1 Leaf mold, 52.9ms\n",
      "image 156/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_02a29ab9-8cba-47a0-bc2f-e7af7dbae149___Crnl_L.Mold 7165.JPG_e8832da4-81cf-4098-90ee-696a23f15156.JPG: 416x416 1 Leaf mold, 42.9ms\n",
      "image 157/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0a9b3ff4-5343-4814-ac2c-fdb3613d4e4d___Crnl_L.Mold 6559.JPG_e365cd00-92d3-4d0b-9a90-73d47a386889.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 158/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ac36661-a47d-47ff-8948-42edec033b87___Crnl_L.Mold 9127.JPG_e869de67-df75-4bfb-8acc-cefb0f17a3ad.JPG: 416x416 1 Leaf mold, 43.9ms\n",
      "image 159/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0adab1d4-5696-4cd8-8453-3931b70e856d___Crnl_L.Mold 8689.JPG_2a77cac1-0467-44c2-8614-bc35d90b533e.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 160/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ae36892-5cb1-476e-8a51-b7fd8183a535___Crnl_L.Mold 6728.JPG_983e7196-4a08-461e-a4bc-422abd78f88d.JPG: 416x416 1 TYLCV, 48.9ms\n",
      "image 161/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0b943ada-01a9-4ce0-a607-e799394856de___Crnl_L.Mold 7008.JPG_ca431072-1fd2-4241-8a6b-032837a311e4.JPG: 416x416 1 Leaf mold, 44.9ms\n",
      "image 162/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0b943ada-01a9-4ce0-a607-e799394856de___Crnl_L.Mold 7008.JPG_ee0a2f67-5e57-4108-90cc-6128bcaa01f7.JPG: 416x416 1 Leaf mold, 1 TYLCV, 43.9ms\n",
      "image 163/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0bae0514-799a-479f-a407-ad763f458916___Crnl_L.Mold 8989.JPG_ab63cb11-8936-407c-8ed1-b29493352fa8.JPG: 416x416 1 Leaf mold, 46.9ms\n",
      "image 164/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0bae0514-799a-479f-a407-ad763f458916___Crnl_L.Mold 8989.JPG_d2587e03-13fb-405f-9aa1-b02801f6f1f2.JPG: 416x416 2 Leaf molds, 44.9ms\n",
      "image 165/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0bb34c9b-ecf7-4fb1-8ee1-098bccdcdaae___Crnl_L.Mold 6522.JPG_608f0f75-a6ac-4ef1-a1d8-e3ebeff526a1.JPG: 416x416 2 Leaf molds, 43.9ms\n",
      "image 166/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0bc63b4c-e41b-4338-a8ac-af664048fdbb___Crnl_L.Mold 6913.JPG_2874d9d0-614b-4cd4-a213-902fca7f230b.JPG: 416x416 1 Leaf mold, 41.9ms\n",
      "image 167/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0bc8fe4f-f614-43ce-bb2f-e3c0ef79f148___Crnl_L.Mold 8907.JPG_ed22ae35-f5de-459e-af3a-a4a6de373e30.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 168/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0c0debed-e807-4236-a2e3-d9b72f54367f___Crnl_L.Mold 6899.JPG_87f4fb93-c54a-49be-8574-c87ec3709115.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 169/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0d54c850-da9a-498d-a636-ddeac067fd7e___Crnl_L.Mold 6746.JPG_46cf579b-8337-46fc-b5ae-1ac5ab618e0c.JPG: 416x416 (no detections), 42.9ms\n",
      "image 170/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0db4cbf4-fa94-42c8-8bf5-90114281c569___Crnl_L.Mold 8681.JPG_b7fa9c45-57dc-4f02-aed1-8bf269442670.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 171/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ddf82ad-9004-4913-ac9c-d00333d7c858___Crnl_L.Mold 7089.JPG_9e1a8887-701e-4b57-804c-ca38e2828a6a.JPG: 416x416 1 TYLCV, 44.9ms\n",
      "image 172/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0de02a32-f166-4d67-bbb8-689e96d04c44___Crnl_L.Mold 8811.JPG_d3a734f4-74b7-494e-977a-d1fde8d6302b.JPG: 416x416 1 healthy, 1 Leaf mold, 47.9ms\n",
      "image 173/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0e508a3f-af06-4c8a-be78-5c38d2d4fb68___Crnl_L.Mold 6775.JPG_40cab4eb-a3b3-48d4-8d4c-dac439e7c93c.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 174/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ed11606-167f-4951-9a07-ffaa7e2aa88a___Crnl_L.Mold 6831.JPG_eecdf736-90c0-4890-9c46-db6a29deb62f.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 175/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ed11606-167f-4951-9a07-ffaa7e2aa88a___Crnl_L.Mold 6831.JPG_f900bb01-72ed-4e15-9501-1b43450ec9eb.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 176/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0eda4dc5-7f7b-4e27-9e53-1e0326eef88e___Crnl_L.Mold 8850.JPG_00695177-a137-41a2-8821-a61e5c5f436b.JPG: 416x416 1 Leaf mold, 46.9ms\n",
      "image 177/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ee63bfa-d01f-4adb-b954-924f271a4d4f___Crnl_L.Mold 9022.JPG_0a5f6b0a-e617-49b4-8a75-bc92476b64f8.JPG: 416x416 1 Leaf mold, 41.9ms\n",
      "image 178/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0ee63bfa-d01f-4adb-b954-924f271a4d4f___Crnl_L.Mold 9022.JPG_c9629a0c-e36c-4377-8b66-fd3a9c11156a.JPG: 416x416 1 Leaf mold, 45.9ms\n",
      "image 179/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0f1ce7cf-da72-4ddb-9bdb-a1af620537c6___Crnl_L.Mold 6840.JPG_0c5c448c-a675-4416-8bc4-f6ecf0b195ef.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 180/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0f1ce7cf-da72-4ddb-9bdb-a1af620537c6___Crnl_L.Mold 6840.JPG_8f9d3cf5-4091-45c0-aef2-b7a88bbfa7aa.JPG: 416x416 (no detections), 43.9ms\n",
      "image 181/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0f1ce7cf-da72-4ddb-9bdb-a1af620537c6___Crnl_L.Mold 6840.JPG_b8a88add-5d5d-4d30-8614-4b37fa87fbf8.JPG: 416x416 1 TYLCV, 39.9ms\n",
      "image 182/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0fd01669-64ab-4042-9715-bf1bcb2ccfbf___Crnl_L.Mold 6996.JPG_35e59884-73cb-464f-8c3c-b0447923395e.JPG: 416x416 1 Leaf mold, 1 TYLCV, 55.9ms\n",
      "image 183/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_0fd01669-64ab-4042-9715-bf1bcb2ccfbf___Crnl_L.Mold 6996.JPG_96f0b5c9-fd66-482a-9731-6fedc0d3f8d7.JPG: 416x416 1 Leaf mold, 1 TYLCV, 47.9ms\n",
      "image 184/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1a1acd8f-bd8d-47be-945d-ce308dffd678___Crnl_L.Mold 6675.JPG_3e7d443f-231f-4bd7-b46c-c252d305e1f5.JPG: 416x416 1 Leaf mold, 47.9ms\n",
      "image 185/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1a1acd8f-bd8d-47be-945d-ce308dffd678___Crnl_L.Mold 6675.JPG_979a8256-c462-43cb-a1e6-7b196cbb8de0.JPG: 416x416 1 Leaf mold, 46.9ms\n",
      "image 186/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1b2db321-28cd-4e33-88eb-b6c1302ca033___Crnl_L.Mold 6701.JPG_9fa371d5-742c-4042-bd80-55bbd7be4476.JPG: 416x416 1 TYLCV, 40.9ms\n",
      "image 187/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1b2db321-28cd-4e33-88eb-b6c1302ca033___Crnl_L.Mold 6701.JPG_d5942342-304d-4af2-b190-af4f3d681b93.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 188/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1bfe7244-44ab-4fac-abe5-f229217cdf0b___Crnl_L.Mold 6815.JPG_24dc7c66-cc96-452c-9980-981558a883e3.JPG: 416x416 1 Leaf mold, 51.9ms\n",
      "image 189/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1bfe7244-44ab-4fac-abe5-f229217cdf0b___Crnl_L.Mold 6815.JPG_676dff59-729f-4c7e-809d-507d1a6adf28.JPG: 416x416 1 TYLCV, 46.9ms\n",
      "image 190/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1c03ffcb-9476-453c-96be-5bd1f629b2d1___Crnl_L.Mold 8853.JPG_b8cbb748-0c9f-4518-a8fa-90b8eb8a665d.JPG: 416x416 1 Leaf mold, 46.9ms\n",
      "image 191/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1ed685c5-7ed4-497e-b9dc-f2851fe7d865___Crnl_L.Mold 6828.JPG_5071bce6-7c56-4a2c-bbbc-87b8b3fb7320.JPG: 416x416 2 TYLCVs, 43.9ms\n",
      "image 192/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1ed685c5-7ed4-497e-b9dc-f2851fe7d865___Crnl_L.Mold 6828.JPG_cb389589-7f11-4e29-8c97-140157ee8430.JPG: 416x416 1 TYLCV, 41.9ms\n",
      "image 193/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1f5c3b37-5590-4db7-a702-0cd93db0c929___Crnl_L.Mold 6930.JPG_5ad6595a-df88-4e7f-8a6d-4549b889c3f4.JPG: 416x416 2 TYLCVs, 43.9ms\n",
      "image 194/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1f5c3b37-5590-4db7-a702-0cd93db0c929___Crnl_L.Mold 6930.JPG_8c669405-9f99-4836-9458-58925a2118fb.JPG: 416x416 1 Leaf mold, 1 TYLCV, 43.9ms\n",
      "image 195/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1f64f046-46e6-47b3-91ef-31c2433face3___Crnl_L.Mold 9089.JPG_e9c9573c-7304-4565-be4f-8368f7cc1a36.JPG: 416x416 1 TYLCV, 42.9ms\n",
      "image 196/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1fa78650-4f81-4c8f-9190-91f1057d1158___Crnl_L.Mold 9083.JPG_6956ede6-4e22-44af-b771-949a79395f3a.JPG: 416x416 1 Leaf mold, 47.9ms\n",
      "image 197/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_1fef5c8b-7d83-45b5-9031-f636c3dc44ae___Crnl_L.Mold 8953.JPG_3de39797-66bc-4447-be91-c49abb47c69f.JPG: 416x416 1 Leaf mold, 58.8ms\n",
      "image 198/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2a15214d-cee6-4359-8baa-7281f3fc0182___Crnl_L.Mold 8672.JPG_1ecc6c1d-aa31-4af7-91ab-1201f0637e7b.JPG: 416x416 1 Leaf mold, 1 TYLCV, 56.8ms\n",
      "image 199/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2aa4f976-9ac1-496d-9b58-0ec03e4bbad8___Crnl_L.Mold 7067.JPG_4e754df9-6f7e-4841-bb60-e8cf8894f744.JPG: 416x416 (no detections), 60.8ms\n",
      "image 200/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b31c158-d7d5-4625-b13b-e3e626d791ff___Crnl_L.Mold 6665.JPG_12ef74db-dd6c-4679-b5f7-b1779d1336e0.JPG: 416x416 1 healthy, 1 Leaf mold, 1 TYLCV, 57.8ms\n",
      "image 201/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b31c158-d7d5-4625-b13b-e3e626d791ff___Crnl_L.Mold 6665.JPG_26841f50-45c6-41a9-9605-7403e56e67d9.JPG: 416x416 1 TYLCV, 67.8ms\n",
      "image 202/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b31c158-d7d5-4625-b13b-e3e626d791ff___Crnl_L.Mold 6665.JPG_afdb5520-085d-481c-9a32-2dd36eec6fd1.JPG: 416x416 1 Leaf mold, 59.8ms\n",
      "image 203/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b727376-492d-47dd-983a-c8f9c7ab386a___Crnl_L.Mold 6556.JPG_0bcb1f4a-cffd-4952-8bb7-72ad8495ea52.JPG: 416x416 1 TYLCV, 54.9ms\n",
      "image 204/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b8557bc-3b98-4169-826c-628c5a683d70___Crnl_L.Mold 6539.JPG_cdfbaa44-b421-42e0-8d87-25db7d34d33c.JPG: 416x416 1 Leaf mold, 58.8ms\n",
      "image 205/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b8557bc-3b98-4169-826c-628c5a683d70___Crnl_L.Mold 6539.JPG_dbb2e2ce-bae2-4d1d-a2c7-557012f91b0d.JPG: 416x416 1 TYLCV, 52.9ms\n",
      "image 206/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\Tomato___Leaf_Mold_original_2b8e612f-7448-44f7-899c-95b3c8291824___Crnl_L.Mold 6671.JPG_193dbe1f-6f00-4f68-9298-e66a0a57cb5a.JPG: 416x416 1 healthy, 56.8ms\n",
      "image 207/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_0_0.jpg: 288x416 1 Leaf mold, 44.9ms\n",
      "image 208/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_0_1.jpg: 320x416 1 Leaf mold, 45.9ms\n",
      "image 209/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_0_2.jpg: 320x416 2 Leaf molds, 43.9ms\n",
      "image 210/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_0_3.jpg: 320x416 1 Leaf mold, 45.9ms\n",
      "image 211/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_0_4.jpg: 416x352 3 Leaf molds, 62.8ms\n",
      "image 212/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_1_0.jpg: 320x416 (no detections), 46.9ms\n",
      "image 213/213 C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo\\test\\images\\disease_1_1.jpg: 288x416 (no detections), 41.9ms\n",
      "Speed: 1.5ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"data/tomato_yolo/test/images/\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c840-f534-4427-a7b3-faf43b1ce4e4",
   "metadata": {},
   "source": [
    "C:\\Users\\acorn\\AppData\\Roaming\\Ultralytics\n",
    "\n",
    "\n",
    "\n",
    "settings.yaml 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac688b-4026-49da-b634-0fef1846fcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7da0b-f9f7-477a-8dba-95a8b63b47fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46413a-889d-4129-89c4-5773652c7606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d80822-6fbb-4c84-a74b-eda83e7de1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be561e-ad85-4f4b-b94f-073a0fad1b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950876e2-18bd-442f-b969-7181a74dbb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5109be-de82-427e-9a45-bccdec8f3dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf7799-66f8-42a1-8d4d-9be035dd187c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9b2b2-8b29-42a0-a424-032bf40b334c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6795900-b34c-4beb-904a-8eb0e5cc3dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d5603-45e4-4012-8de2-ac6dffbfc2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9c784f5-c30f-41ad-a03b-f0d54ace9f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.124 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.117  Python-3.9.13 torch-2.0.1+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml, epochs=3, patience=15, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training : 2023-06-29 10:01:41.040306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train5', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\train\\labels... 25446 images, 0 backgrounds, 0 corrupt:\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\val\\labels... 4934 images, 0 backgrounds, 0 corrupt: 100%\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\val\\labels.cache\n",
      "Plotting labels to runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G      1.004      1.483       1.25         16        416: 100%|██████████| 796/796 [1:30:08<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [06:23\n",
      "                   all       4934       4934      0.726       0.76      0.762      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G     0.9483     0.9978      1.205         15        416: 100%|██████████| 796/796 [1:26:43<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [06:34\n",
      "                   all       4934       4934      0.787      0.824      0.852      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G     0.8761       0.87      1.168         15        416: 100%|██████████| 796/796 [1:27:17<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [06:31\n",
      "                   all       4934       4934      0.856      0.835      0.872       0.71\n",
      "\n",
      "3 epochs completed in 4.729 hours.\n",
      "Optimizer stripped from runs\\detect\\train5\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train5\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train5\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.117  Python-3.9.13 torch-2.0.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [04:44\n",
      "                   all       4934       4934      0.856      0.836      0.872       0.71\n",
      "               healthy       4934       1888      0.951      0.986      0.991      0.945\n",
      "             Leaf mold       4934       1210      0.871      0.847      0.879      0.657\n",
      "                 TYLCV       4934       1836      0.748      0.674      0.746      0.528\n",
      "Speed: 0.6ms preprocess, 39.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Training : 2023-06-29 14:50:59.434569\n",
      "\n",
      "Time taken : 4:49:18.394263\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start Training :\", start_time)\n",
    "##########\n",
    "\n",
    "\n",
    "model.train(data=\"C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml\",\n",
    "            epochs=3, patience=15,\n",
    "            batch=32, imgsz=416)\n",
    "\n",
    "\n",
    "##########\n",
    "end_time = datetime.now()\n",
    "print(\"End of Training :\", end_time)\n",
    "print(\"\\nTime taken :\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f78ee8-0612-4bfa-bf1e-e392d2f1cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(\"Start Training :\", start_time)\n",
    "# ##########\n",
    "\n",
    "\n",
    "# model.train(data=\"C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml\",\n",
    "#             epochs=3, patience=15,\n",
    "#             batch=32, imgsz=416)\n",
    "\n",
    "\n",
    "# ##########\n",
    "# end_time = datetime.now()\n",
    "# print(\"End of Training :\", end_time)\n",
    "# print(\"\\nTime taken :\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c0bb6-8492-4190-a5a9-cf26604991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "New https://pypi.org/project/ultralytics/8.0.124 available  Update with 'pip install -U ultralytics'\n",
    "Ultralytics YOLOv8.0.117  Python-3.9.13 torch-2.0.1+cpu CPU\n",
    "yolo\\engine\\trainer: task=detect, mode=train, model=yolov8n.pt, data=C:/juna27/PythonWork/AI/data/tomato_yolo_resize/tom_out_leaf.yaml, epochs=3, patience=15, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n",
    "\n",
    "                   from  n    params  module                                       arguments                     \n",
    "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
    "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
    "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
    "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
    "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
    "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
    "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
    "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
    "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
    "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
    " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
    " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
    " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
    " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
    " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
    " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
    " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
    " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
    " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
    " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
    " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
    " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
    " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
    "Model summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
    "Start Training : 2023-06-29 10:01:41.040306\n",
    "\n",
    "Transferred 355/355 items from pretrained weights\n",
    "TensorBoard: Start with 'tensorboard --logdir runs\\detect\\train5', view at http://localhost:6006/\n",
    "train: Scanning C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\train\\labels... 25446 images, 0 backgrounds, 0 corrupt:\n",
    "train: New cache created: C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\train\\labels.cache\n",
    "val: Scanning C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\val\\labels... 4934 images, 0 backgrounds, 0 corrupt: 100%\n",
    "val: New cache created: C:\\juna27\\PythonWork\\AI\\data\\tomato_yolo_resize\\val\\labels.cache\n",
    "Plotting labels to runs\\detect\\train5\\labels.jpg... \n",
    "optimizer: AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
    "Image sizes 416 train, 416 val\n",
    "Using 0 dataloader workers\n",
    "Logging results to runs\\detect\\train5\n",
    "Starting training for 3 epochs...\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
    "        1/3         0G      1.004      1.483       1.25         16        416: 100%|██████████| 796/796 [1:30:08<00:00,\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [06:23\n",
    "                   all       4934       4934      0.726       0.76      0.762      0.572\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
    "        2/3         0G     0.9483     0.9978      1.205         15        416: 100%|██████████| 796/796 [1:26:43<00:00,\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [06:34\n",
    "                   all       4934       4934      0.787      0.824      0.852      0.678\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
    "        3/3         0G     0.8761       0.87      1.168         15        416: 100%|██████████| 796/796 [1:27:17<00:00,\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [06:31\n",
    "                   all       4934       4934      0.856      0.835      0.872       0.71\n",
    "\n",
    "3 epochs completed in 4.729 hours.\n",
    "Optimizer stripped from runs\\detect\\train5\\weights\\last.pt, 6.2MB\n",
    "Optimizer stripped from runs\\detect\\train5\\weights\\best.pt, 6.2MB\n",
    "\n",
    "Validating runs\\detect\\train5\\weights\\best.pt...\n",
    "Ultralytics YOLOv8.0.117  Python-3.9.13 torch-2.0.1+cpu CPU\n",
    "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 78/78 [04:44\n",
    "                   all       4934       4934      0.856      0.836      0.872       0.71\n",
    "               healthy       4934       1888      0.951      0.986      0.991      0.945\n",
    "             Leaf mold       4934       1210      0.871      0.847      0.879      0.657\n",
    "                 TYLCV       4934       1836      0.748      0.674      0.746      0.528\n",
    "Speed: 0.6ms preprocess, 39.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
    "Results saved to runs\\detect\\train5\n",
    "End of Training : 2023-06-29 14:50:59.434569\n",
    "\n",
    "Time taken : 4:49:18.394263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d019ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039b65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6fa27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348dcaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6eec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "input_directory = \"\"\n",
    "\n",
    "output_directory = \"\"\n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    # 파일 경로\n",
    "    input_image_path = os.path.join(input_directory, filename)\n",
    "    # read\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "\n",
    "    # w, h\n",
    "    width = input_image.shape[1]\n",
    "    height = input_image.shape[0]\n",
    "\n",
    "    # resize\n",
    "    output_image = cv2.resize(input_image, dsize=(width // 4, height // 4))\n",
    "\n",
    "    # 경로\n",
    "    output_image_path = os.path.join(output_directory, filename)\n",
    "\n",
    "    # 저장\n",
    "    cv2.imwrite(output_image_path, output_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
