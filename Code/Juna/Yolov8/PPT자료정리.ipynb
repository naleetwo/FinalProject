{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b71da82-5c10-4a40-a138-11893b2b44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815a43f9-0bc7-4a0d-87f8-fea397e623d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # 현재 경로와 하위 디렉토리 검색 함수\n",
    "# def search_directories(root):\n",
    "#     directories = []\n",
    "#     for dirpath, dirnames, filenames in os.walk(root):\n",
    "#         if \"results.csv\" in filenames:\n",
    "#             directories.append(dirpath)\n",
    "#     return directories\n",
    "\n",
    "# # 데이터프레임 생성 함수\n",
    "# def create_dataframe(directory):\n",
    "#     file_path = os.path.join(directory, \"results.csv\")\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     return df\n",
    "\n",
    "# # 경로 설정\n",
    "# root_path = \"C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\"  # 실제 경로로 변경해야 합니다.\n",
    "\n",
    "# # 폴더 검색 및 데이터프레임 생성\n",
    "# directories = search_directories(root_path)\n",
    "# dataframes = [create_dataframe(directory) for directory in directories]\n",
    "\n",
    "# # 데이터프레임 출력 및 폴더 이름 출력\n",
    "# for i, df in enumerate(dataframes):\n",
    "#     print(f\"Folder: {directories[i]}\")\n",
    "#     print(df)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1534ef07-095b-40f9-a901-c8698da85d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b1698-fde1-4d8c-a9ce-4e951b119f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7b5a8-4ce0-4763-a2b2-cfb744bb22c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b11870-cc03-4923-bccc-851e53200c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172ad1e1-e765-428d-b17b-4ce8b3e9e620",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 resize Epochs20_batch_32_imgsz416\n",
      "                      epoch           train/box_loss           train/cls_loss  \\\n",
      "0                         0                  0.89871                  0.95886   \n",
      "1                         1                  0.97987                  0.98803   \n",
      "2                         2                  0.96781                  0.95245   \n",
      "3                         3                  0.94518                  0.91246   \n",
      "4                         4                  0.90728                  0.87481   \n",
      "5                         5                  0.87810                  0.82732   \n",
      "6                         6                  0.85686                  0.80637   \n",
      "7                         7                  0.84006                  0.78498   \n",
      "8                         8                  0.82358                  0.76334   \n",
      "9                         9                  0.80213                  0.73779   \n",
      "10                       10                  0.79180                  0.72055   \n",
      "11                       11                  0.77494                  0.70086   \n",
      "12                       12                  0.76201                  0.68417   \n",
      "13                       13                  0.74984                  0.67548   \n",
      "14                       14                  0.73398                  0.65026   \n",
      "15                       15                  0.72217                  0.63458   \n",
      "16                       16                  0.70481                  0.61986   \n",
      "17                       17                  0.69696                  0.60523   \n",
      "18                       18                  0.68686                  0.58972   \n",
      "19                       19                  0.67504                  0.57737   \n",
      "\n",
      "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                    1.1810                  0.74300                  0.73351   \n",
      "1                    1.2168                  0.85138                  0.83251   \n",
      "2                    1.2111                  0.85414                  0.81504   \n",
      "3                    1.1957                  0.86043                  0.84120   \n",
      "4                    1.1772                  0.84712                  0.82450   \n",
      "5                    1.1610                  0.89106                  0.84161   \n",
      "6                    1.1506                  0.88350                  0.84658   \n",
      "7                    1.1447                  0.88589                  0.86392   \n",
      "8                    1.1368                  0.90431                  0.84272   \n",
      "9                    1.1249                  0.88994                  0.86274   \n",
      "10                   1.1183                  0.88716                  0.86078   \n",
      "11                   1.1079                  0.88809                  0.85616   \n",
      "12                   1.1039                  0.88596                  0.87778   \n",
      "13                   1.0944                  0.89994                  0.85683   \n",
      "14                   1.0876                  0.91219                  0.85377   \n",
      "15                   1.0799                  0.90204                  0.86161   \n",
      "16                   1.0738                  0.90350                  0.85855   \n",
      "17                   1.0692                  0.89539                  0.87091   \n",
      "18                   1.0632                  0.90237                  0.86136   \n",
      "19                   1.0592                  0.90532                  0.85850   \n",
      "\n",
      "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                   0.76658                  0.57865                  0.81670   \n",
      "1                   0.87052                  0.69120                  0.72940   \n",
      "2                   0.86918                  0.67512                  0.78431   \n",
      "3                   0.88171                  0.69897                  0.72953   \n",
      "4                   0.86521                  0.70788                  0.68655   \n",
      "5                   0.88911                  0.73276                  0.65941   \n",
      "6                   0.88719                  0.73376                  0.63772   \n",
      "7                   0.89585                  0.75284                  0.59818   \n",
      "8                   0.90322                  0.75933                  0.59371   \n",
      "9                   0.91052                  0.76803                  0.59082   \n",
      "10                  0.90554                  0.76616                  0.57007   \n",
      "11                  0.90711                  0.77101                  0.56238   \n",
      "12                  0.91441                  0.77737                  0.56289   \n",
      "13                  0.91100                  0.77600                  0.55184   \n",
      "14                  0.91263                  0.77853                  0.55196   \n",
      "15                  0.91403                  0.78242                  0.53595   \n",
      "16                  0.91599                  0.78249                  0.53842   \n",
      "17                  0.91336                  0.77900                  0.53673   \n",
      "18                  0.91404                  0.78047                  0.53094   \n",
      "19                  0.91386                  0.78099                  0.53665   \n",
      "\n",
      "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                   1.00760                  1.14230                 0.000476   \n",
      "1                   0.68469                  1.08390                 0.000905   \n",
      "2                   0.73477                  1.11560                 0.001287   \n",
      "3                   0.68654                  1.08020                 0.001217   \n",
      "4                   0.65895                  1.07150                 0.001217   \n",
      "5                   0.57940                  1.06410                 0.001146   \n",
      "6                   0.58078                  1.04410                 0.001075   \n",
      "7                   0.53761                  1.02330                 0.001005   \n",
      "8                   0.52786                  1.01370                 0.000934   \n",
      "9                   0.50186                  1.01800                 0.000863   \n",
      "10                  0.50717                  1.01020                 0.000792   \n",
      "11                  0.50837                  0.99873                 0.000722   \n",
      "12                  0.48083                  1.00300                 0.000651   \n",
      "13                  0.48471                  0.99550                 0.000580   \n",
      "14                  0.47646                  1.00070                 0.000509   \n",
      "15                  0.47557                  0.98911                 0.000439   \n",
      "16                  0.47370                  0.99497                 0.000368   \n",
      "17                  0.47797                  0.99229                 0.000297   \n",
      "18                  0.47586                  0.99051                 0.000227   \n",
      "19                  0.48239                  0.99481                 0.000156   \n",
      "\n",
      "                     lr/pg1                   lr/pg2  \n",
      "0                  0.000476                 0.000476  \n",
      "1                  0.000905                 0.000905  \n",
      "2                  0.001287                 0.001287  \n",
      "3                  0.001217                 0.001217  \n",
      "4                  0.001217                 0.001217  \n",
      "5                  0.001146                 0.001146  \n",
      "6                  0.001075                 0.001075  \n",
      "7                  0.001005                 0.001005  \n",
      "8                  0.000934                 0.000934  \n",
      "9                  0.000863                 0.000863  \n",
      "10                 0.000792                 0.000792  \n",
      "11                 0.000722                 0.000722  \n",
      "12                 0.000651                 0.000651  \n",
      "13                 0.000580                 0.000580  \n",
      "14                 0.000509                 0.000509  \n",
      "15                 0.000439                 0.000439  \n",
      "16                 0.000368                 0.000368  \n",
      "17                 0.000297                 0.000297  \n",
      "18                 0.000227                 0.000227  \n",
      "19                 0.000156                 0.000156  \n",
      "\n",
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 resize Epochs30_batch_32_imgsz416\n",
      "                      epoch           train/box_loss           train/cls_loss  \\\n",
      "0                         0                  0.98252                  1.83730   \n",
      "1                         1                  0.95776                  1.17470   \n",
      "2                         2                  1.02630                  1.12530   \n",
      "3                         3                  1.05520                  1.08990   \n",
      "4                         4                  0.99138                  0.98886   \n",
      "5                         5                  0.95184                  0.92604   \n",
      "6                         6                  0.92290                  0.88459   \n",
      "7                         7                  0.90121                  0.86108   \n",
      "8                         8                  0.88255                  0.83060   \n",
      "9                         9                  0.86180                  0.80638   \n",
      "10                       10                  0.85153                  0.79071   \n",
      "11                       11                  0.83636                  0.77448   \n",
      "12                       12                  0.81999                  0.75839   \n",
      "13                       13                  0.80790                  0.74601   \n",
      "14                       14                  0.79838                  0.72310   \n",
      "15                       15                  0.78836                  0.71055   \n",
      "16                       16                  0.77066                  0.70166   \n",
      "17                       17                  0.76677                  0.69116   \n",
      "18                       18                  0.75574                  0.67589   \n",
      "19                       19                  0.74448                  0.66252   \n",
      "20                       20                  0.73725                  0.64624   \n",
      "21                       21                  0.72882                  0.63383   \n",
      "22                       22                  0.71630                  0.62221   \n",
      "23                       23                  0.70318                  0.60951   \n",
      "24                       24                  0.70155                  0.60475   \n",
      "25                       25                  0.68812                  0.59201   \n",
      "26                       26                  0.67781                  0.57469   \n",
      "27                       27                  0.66846                  0.56226   \n",
      "28                       28                  0.66006                  0.54927   \n",
      "29                       29                  0.65114                  0.53709   \n",
      "\n",
      "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                    1.2435                  0.79243                  0.79363   \n",
      "1                    1.1999                  0.82497                  0.81294   \n",
      "2                    1.2401                  0.74635                  0.69058   \n",
      "3                    1.2506                  0.83196                  0.79026   \n",
      "4                    1.2191                  0.88281                  0.82738   \n",
      "5                    1.1980                  0.88356                  0.84958   \n",
      "6                    1.1825                  0.87861                  0.82954   \n",
      "7                    1.1733                  0.86992                  0.86217   \n",
      "8                    1.1616                  0.88595                  0.85228   \n",
      "9                    1.1502                  0.88056                  0.86310   \n",
      "10                   1.1445                  0.87544                  0.86223   \n",
      "11                   1.1355                  0.87751                  0.86178   \n",
      "12                   1.1291                  0.88558                  0.86250   \n",
      "13                   1.1231                  0.88651                  0.86462   \n",
      "14                   1.1182                  0.90203                  0.85104   \n",
      "15                   1.1101                  0.88638                  0.86473   \n",
      "16                   1.1032                  0.90235                  0.86324   \n",
      "17                   1.1014                  0.87690                  0.88166   \n",
      "18                   1.0975                  0.88234                  0.86815   \n",
      "19                   1.0910                  0.88857                  0.87715   \n",
      "20                   1.0858                  0.88426                  0.88084   \n",
      "21                   1.0830                  0.90285                  0.86838   \n",
      "22                   1.0760                  0.90468                  0.87134   \n",
      "23                   1.0685                  0.89587                  0.87328   \n",
      "24                   1.0680                  0.89103                  0.87804   \n",
      "25                   1.0614                  0.90482                  0.86956   \n",
      "26                   1.0563                  0.89515                  0.88066   \n",
      "27                   1.0514                  0.89424                  0.87515   \n",
      "28                   1.0486                  0.89679                  0.87398   \n",
      "29                   1.0430                  0.89764                  0.87507   \n",
      "\n",
      "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                   0.83644                  0.65564                  0.69575   \n",
      "1                   0.85251                  0.66818                  0.73540   \n",
      "2                   0.74259                  0.52071                  1.03720   \n",
      "3                   0.83457                  0.63947                  0.81101   \n",
      "4                   0.87618                  0.70253                  0.72257   \n",
      "5                   0.89613                  0.72922                  0.66736   \n",
      "6                   0.88788                  0.71913                  0.68893   \n",
      "7                   0.90068                  0.74660                  0.62789   \n",
      "8                   0.89965                  0.74791                  0.62686   \n",
      "9                   0.90427                  0.74871                  0.63240   \n",
      "10                  0.90133                  0.76174                  0.58737   \n",
      "11                  0.89815                  0.75985                  0.58624   \n",
      "12                  0.90378                  0.76469                  0.58051   \n",
      "13                  0.90722                  0.77201                  0.56991   \n",
      "14                  0.91202                  0.77692                  0.56345   \n",
      "15                  0.91074                  0.77687                  0.55344   \n",
      "16                  0.91690                  0.77995                  0.54888   \n",
      "17                  0.90846                  0.77660                  0.54097   \n",
      "18                  0.91074                  0.77429                  0.54072   \n",
      "19                  0.91741                  0.78120                  0.53785   \n",
      "20                  0.91525                  0.77888                  0.53504   \n",
      "21                  0.91798                  0.78196                  0.53472   \n",
      "22                  0.91787                  0.78202                  0.52845   \n",
      "23                  0.91692                  0.77833                  0.53361   \n",
      "24                  0.91594                  0.78104                  0.52738   \n",
      "25                  0.91764                  0.78245                  0.52624   \n",
      "26                  0.92054                  0.78124                  0.52730   \n",
      "27                  0.91791                  0.77881                  0.53205   \n",
      "28                  0.91797                  0.77722                  0.53559   \n",
      "29                  0.91579                  0.77465                  0.53870   \n",
      "\n",
      "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                   1.11280                  1.08360                 0.003329   \n",
      "1                   0.84830                  1.09830                 0.006443   \n",
      "2                   1.26140                  1.28180                 0.009336   \n",
      "3                   0.78649                  1.13790                 0.009010   \n",
      "4                   0.66769                  1.09100                 0.009010   \n",
      "5                   0.59495                  1.05630                 0.008680   \n",
      "6                   0.63243                  1.06740                 0.008350   \n",
      "7                   0.56466                  1.03940                 0.008020   \n",
      "8                   0.56658                  1.03170                 0.007690   \n",
      "9                   0.53715                  1.03690                 0.007360   \n",
      "10                  0.53037                  1.01670                 0.007030   \n",
      "11                  0.53500                  1.01500                 0.006700   \n",
      "12                  0.51373                  1.01300                 0.006370   \n",
      "13                  0.50456                  1.00580                 0.006040   \n",
      "14                  0.48515                  1.00200                 0.005710   \n",
      "15                  0.48761                  0.99785                 0.005380   \n",
      "16                  0.47723                  0.99398                 0.005050   \n",
      "17                  0.48003                  0.98922                 0.004720   \n",
      "18                  0.47700                  0.99617                 0.004390   \n",
      "19                  0.46528                  0.99044                 0.004060   \n",
      "20                  0.47205                  0.98893                 0.003730   \n",
      "21                  0.46907                  0.98775                 0.003400   \n",
      "22                  0.46943                  0.98449                 0.003070   \n",
      "23                  0.47216                  0.98821                 0.002740   \n",
      "24                  0.47456                  0.98604                 0.002410   \n",
      "25                  0.47106                  0.98656                 0.002080   \n",
      "26                  0.47175                  0.98732                 0.001750   \n",
      "27                  0.47796                  0.99148                 0.001420   \n",
      "28                  0.47957                  0.99372                 0.001090   \n",
      "29                  0.47819                  0.99748                 0.000760   \n",
      "\n",
      "                     lr/pg1                   lr/pg2  \n",
      "0                  0.003329                 0.003329  \n",
      "1                  0.006443                 0.006443  \n",
      "2                  0.009336                 0.009336  \n",
      "3                  0.009010                 0.009010  \n",
      "4                  0.009010                 0.009010  \n",
      "5                  0.008680                 0.008680  \n",
      "6                  0.008350                 0.008350  \n",
      "7                  0.008020                 0.008020  \n",
      "8                  0.007690                 0.007690  \n",
      "9                  0.007360                 0.007360  \n",
      "10                 0.007030                 0.007030  \n",
      "11                 0.006700                 0.006700  \n",
      "12                 0.006370                 0.006370  \n",
      "13                 0.006040                 0.006040  \n",
      "14                 0.005710                 0.005710  \n",
      "15                 0.005380                 0.005380  \n",
      "16                 0.005050                 0.005050  \n",
      "17                 0.004720                 0.004720  \n",
      "18                 0.004390                 0.004390  \n",
      "19                 0.004060                 0.004060  \n",
      "20                 0.003730                 0.003730  \n",
      "21                 0.003400                 0.003400  \n",
      "22                 0.003070                 0.003070  \n",
      "23                 0.002740                 0.002740  \n",
      "24                 0.002410                 0.002410  \n",
      "25                 0.002080                 0.002080  \n",
      "26                 0.001750                 0.001750  \n",
      "27                 0.001420                 0.001420  \n",
      "28                 0.001090                 0.001090  \n",
      "29                 0.000760                 0.000760  \n",
      "\n",
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 resize(w,h 각 0.25배) Epochs4_batch_32_imgsz416\n",
      "                     epoch           train/box_loss           train/cls_loss  \\\n",
      "0                        0                  1.00380                  1.48350   \n",
      "1                        1                  0.94826                  0.99781   \n",
      "2                        2                  0.87608                  0.87002   \n",
      "\n",
      "            train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                   1.2499                  0.72632                  0.76036   \n",
      "1                   1.2048                  0.78734                  0.82355   \n",
      "2                   1.1684                  0.85647                  0.83541   \n",
      "\n",
      "          metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                  0.76198                  0.57244                  0.79767   \n",
      "1                  0.85151                  0.67836                  0.70087   \n",
      "2                  0.87208                  0.71021                  0.66615   \n",
      "\n",
      "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                  1.13170                   1.1318                 0.000476   \n",
      "1                  0.77589                   1.0744                 0.000638   \n",
      "2                  0.65397                   1.0513                 0.000486   \n",
      "\n",
      "                    lr/pg1                   lr/pg2  \n",
      "0                 0.000476                 0.000476  \n",
      "1                 0.000638                 0.000638  \n",
      "2                 0.000486                 0.000486  \n",
      "\n",
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 resize+shuffle Epochs100_batch_32_imgsz416\n",
      "                      epoch           train/box_loss           train/cls_loss  \\\n",
      "0                         0                  0.96490                  1.82840   \n",
      "1                         1                  0.94748                  1.14970   \n",
      "2                         2                  1.01220                  1.11530   \n",
      "3                         3                  1.05020                  1.07890   \n",
      "4                         4                  0.99577                  0.98411   \n",
      "..                      ...                      ...                      ...   \n",
      "95                       95                  0.54197                  0.39140   \n",
      "96                       96                  0.54501                  0.38888   \n",
      "97                       97                  0.53806                  0.38464   \n",
      "98                       98                  0.53366                  0.37925   \n",
      "99                       99                  0.53853                  0.38273   \n",
      "\n",
      "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                   1.23500                  0.83749                  0.77292   \n",
      "1                   1.19450                  0.80467                  0.76979   \n",
      "2                   1.23310                  0.80015                  0.76479   \n",
      "3                   1.25550                  0.83126                  0.79041   \n",
      "4                   1.22530                  0.84411                  0.80570   \n",
      "..                      ...                      ...                      ...   \n",
      "95                  0.97786                  0.97318                  0.96252   \n",
      "96                  0.97986                  0.97305                  0.96214   \n",
      "97                  0.97584                  0.97383                  0.96097   \n",
      "98                  0.97642                  0.97300                  0.96141   \n",
      "99                  0.97732                  0.97455                  0.96027   \n",
      "\n",
      "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                   0.82800                  0.65284                  0.78202   \n",
      "1                   0.83327                  0.64360                  0.83286   \n",
      "2                   0.81192                  0.58288                  0.98705   \n",
      "3                   0.85077                  0.66129                  0.85244   \n",
      "4                   0.86557                  0.67738                  0.82725   \n",
      "..                      ...                      ...                      ...   \n",
      "95                  0.98715                  0.92328                  0.38608   \n",
      "96                  0.98747                  0.92414                  0.38386   \n",
      "97                  0.98766                  0.92505                  0.38215   \n",
      "98                  0.98788                  0.92608                  0.38012   \n",
      "99                  0.98806                  0.92686                  0.37857   \n",
      "\n",
      "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                   1.19380                  1.10840                 0.003329   \n",
      "1                   1.02930                  1.15860                 0.006596   \n",
      "2                   1.02940                  1.25700                 0.009798   \n",
      "3                   0.83846                  1.16170                 0.009703   \n",
      "4                   0.77935                  1.14950                 0.009703   \n",
      "..                      ...                      ...                      ...   \n",
      "95                  0.24251                  0.86558                 0.000694   \n",
      "96                  0.24020                  0.86411                 0.000595   \n",
      "97                  0.23822                  0.86320                 0.000496   \n",
      "98                  0.23612                  0.86199                 0.000397   \n",
      "99                  0.23451                  0.86084                 0.000298   \n",
      "\n",
      "                     lr/pg1                   lr/pg2  \n",
      "0                  0.003329                 0.003329  \n",
      "1                  0.006596                 0.006596  \n",
      "2                  0.009798                 0.009798  \n",
      "3                  0.009703                 0.009703  \n",
      "4                  0.009703                 0.009703  \n",
      "..                      ...                      ...  \n",
      "95                 0.000694                 0.000694  \n",
      "96                 0.000595                 0.000595  \n",
      "97                 0.000496                 0.000496  \n",
      "98                 0.000397                 0.000397  \n",
      "99                 0.000298                 0.000298  \n",
      "\n",
      "[100 rows x 14 columns]\n",
      "\n",
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 resize+shuffle_7classes Epochs100_batch_32_imgsz416\n",
      "                      epoch           train/box_loss           train/cls_loss  \\\n",
      "0                         0                  0.96287                  2.40580   \n",
      "1                         1                  0.94700                  1.60650   \n",
      "2                         2                  1.01270                  1.54330   \n",
      "3                         3                  1.05150                  1.46920   \n",
      "4                         4                  0.99516                  1.35250   \n",
      "..                      ...                      ...                      ...   \n",
      "95                       95                  0.52903                  0.44878   \n",
      "96                       96                  0.52798                  0.44552   \n",
      "97                       97                  0.52355                  0.43810   \n",
      "98                       98                  0.51882                  0.43133   \n",
      "99                       99                  0.52139                  0.43602   \n",
      "\n",
      "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                   1.23900                  0.45047                  0.59132   \n",
      "1                   1.19300                  0.47858                  0.56141   \n",
      "2                   1.22620                  0.31162                  0.46589   \n",
      "3                   1.24450                  0.27638                  0.48210   \n",
      "4                   1.21370                  0.50370                  0.57183   \n",
      "..                      ...                      ...                      ...   \n",
      "95                  0.96449                  0.97360                  0.95880   \n",
      "96                  0.96516                  0.97366                  0.95948   \n",
      "97                  0.96227                  0.97403                  0.96118   \n",
      "98                  0.96278                  0.97433                  0.96085   \n",
      "99                  0.96346                  0.97430                  0.96098   \n",
      "\n",
      "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                   0.46534                  0.36322                  0.76364   \n",
      "1                   0.46444                  0.35407                  0.83660   \n",
      "2                   0.37150                  0.26155                  1.00810   \n",
      "3                   0.24554                  0.17570                  0.97235   \n",
      "4                   0.48623                  0.37072                  0.84057   \n",
      "..                      ...                      ...                      ...   \n",
      "95                  0.98750                  0.92009                  0.35064   \n",
      "96                  0.98790                  0.92079                  0.34895   \n",
      "97                  0.98824                  0.92193                  0.34728   \n",
      "98                  0.98858                  0.92308                  0.34596   \n",
      "99                  0.98883                  0.92437                  0.34446   \n",
      "\n",
      "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                   1.51310                  1.09650                 0.003329   \n",
      "1                   1.47340                  1.14950                 0.006596   \n",
      "2                   1.76260                  1.25950                 0.009798   \n",
      "3                   2.31800                  1.22760                 0.009703   \n",
      "4                   1.30490                  1.15100                 0.009703   \n",
      "..                      ...                      ...                      ...   \n",
      "95                  0.23651                  0.83986                 0.000694   \n",
      "96                  0.23413                  0.83873                 0.000595   \n",
      "97                  0.23219                  0.83769                 0.000496   \n",
      "98                  0.23054                  0.83696                 0.000397   \n",
      "99                  0.22880                  0.83603                 0.000298   \n",
      "\n",
      "                     lr/pg1                   lr/pg2  \n",
      "0                  0.003329                 0.003329  \n",
      "1                  0.006596                 0.006596  \n",
      "2                  0.009798                 0.009798  \n",
      "3                  0.009703                 0.009703  \n",
      "4                  0.009703                 0.009703  \n",
      "..                      ...                      ...  \n",
      "95                 0.000694                 0.000694  \n",
      "96                 0.000595                 0.000595  \n",
      "97                 0.000496                 0.000496  \n",
      "98                 0.000397                 0.000397  \n",
      "99                 0.000298                 0.000298  \n",
      "\n",
      "[100 rows x 14 columns]\n",
      "\n",
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 원본 Epochs6_batch64_imgsz416\n",
      "                     epoch           train/box_loss           train/cls_loss  \\\n",
      "0                        0                  0.77882                  1.32780   \n",
      "1                        1                  0.76652                  0.84595   \n",
      "2                        2                  0.75293                  0.76196   \n",
      "3                        3                  0.71320                  0.68739   \n",
      "4                        4                  0.68329                  0.65914   \n",
      "5                        5                  0.62639                  0.59493   \n",
      "\n",
      "            train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                   1.1460                  0.45303                  0.47637   \n",
      "1                   1.1188                  0.49370                  0.42200   \n",
      "2                   1.1135                  0.71817                  0.59211   \n",
      "3                   1.0969                  0.81722                  0.52973   \n",
      "4                   1.0845                  0.78871                  0.63686   \n",
      "5                   1.0592                  0.79189                  0.70259   \n",
      "\n",
      "          metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                  0.43280                  0.28655                   1.3955   \n",
      "1                  0.39920                  0.27556                   1.8212   \n",
      "2                  0.64548                  0.44363                   1.5452   \n",
      "3                  0.63623                  0.45125                   1.4919   \n",
      "4                  0.71095                  0.49683                   1.3807   \n",
      "5                  0.78663                  0.56061                   1.2879   \n",
      "\n",
      "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                   1.8049                   1.6499                 0.000553   \n",
      "1                   1.8842                   2.1610                 0.000926   \n",
      "2                   1.3345                   1.7338                 0.001115   \n",
      "3                   1.6075                   1.6947                 0.000842   \n",
      "4                   1.2084                   1.6083                 0.000842   \n",
      "5                   1.0586                   1.4940                 0.000567   \n",
      "\n",
      "                    lr/pg1                   lr/pg2  \n",
      "0                 0.000553                 0.000553  \n",
      "1                 0.000926                 0.000926  \n",
      "2                 0.001115                 0.001115  \n",
      "3                 0.000842                 0.000842  \n",
      "4                 0.000842                 0.000842  \n",
      "5                 0.000567                 0.000567  \n",
      "\n",
      "Folder: C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\\시설 원본 정상 잎만 선택 Epochs8_batch32_imgsz416\n",
      "                     epoch           train/box_loss           train/cls_loss  \\\n",
      "0                        0                  1.00430                  1.47530   \n",
      "1                        1                  0.99014                  1.03430   \n",
      "2                        2                  0.95486                  0.95224   \n",
      "3                        3                  0.91880                  0.89117   \n",
      "4                        4                  0.89151                  0.85509   \n",
      "5                        5                  0.84672                  0.80102   \n",
      "6                        6                  0.81423                  0.75268   \n",
      "7                        7                  0.77222                  0.70639   \n",
      "\n",
      "            train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
      "0                   1.2500                  0.70252                  0.67392   \n",
      "1                   1.2254                  0.79881                  0.81797   \n",
      "2                   1.2051                  0.83734                  0.82623   \n",
      "3                   1.1860                  0.86206                  0.82121   \n",
      "4                   1.1708                  0.85839                  0.83001   \n",
      "5                   1.1506                  0.88506                  0.85606   \n",
      "6                   1.1376                  0.88256                  0.85943   \n",
      "7                   1.1147                  0.88131                  0.87326   \n",
      "\n",
      "          metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
      "0                  0.71140                  0.53011                  0.82528   \n",
      "1                  0.83192                  0.64776                  0.78122   \n",
      "2                  0.84643                  0.67018                  0.75950   \n",
      "3                  0.88074                  0.72244                  0.65868   \n",
      "4                  0.87744                  0.72071                  0.66564   \n",
      "5                  0.89896                  0.74618                  0.61636   \n",
      "6                  0.89949                  0.75760                  0.59784   \n",
      "7                  0.90676                  0.76167                  0.57547   \n",
      "\n",
      "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
      "0                  1.36180                   1.1450                 0.000476   \n",
      "1                  0.76913                   1.1085                 0.000834   \n",
      "2                  0.75705                   1.0940                 0.001075   \n",
      "3                  0.63894                   1.0558                 0.000898   \n",
      "4                  0.65624                   1.0528                 0.000898   \n",
      "5                  0.55284                   1.0278                 0.000722   \n",
      "6                  0.54363                   1.0256                 0.000545   \n",
      "7                  0.51395                   1.0162                 0.000368   \n",
      "\n",
      "                    lr/pg1                   lr/pg2  \n",
      "0                 0.000476                 0.000476  \n",
      "1                 0.000834                 0.000834  \n",
      "2                 0.001075                 0.001075  \n",
      "3                 0.000898                 0.000898  \n",
      "4                 0.000898                 0.000898  \n",
      "5                 0.000722                 0.000722  \n",
      "6                 0.000545                 0.000545  \n",
      "7                 0.000368                 0.000368  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 현재 경로와 하위 디렉토리 검색 함수\n",
    "def search_directories(root):\n",
    "    directories = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        if \"results.csv\" in filenames:\n",
    "            directories.append(dirpath)\n",
    "    return directories\n",
    "\n",
    "# 데이터프레임 생성 함수\n",
    "def create_dataframe(directory):\n",
    "    file_path = os.path.join(directory, \"results.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# 경로 설정\n",
    "root_path = \"C:/Users/acorn/Desktop/(07-05~)Aihub_시설작물질병진단(토마토)자료\" \n",
    "\n",
    "# 폴더 검색 및 데이터프레임 생성\n",
    "directories = search_directories(root_path)\n",
    "dataframes = []\n",
    "\n",
    "# 데이터프레임 생성 및 변수 할당\n",
    "for i, directory in enumerate(directories):\n",
    "    df_name = f\"df_{i+1}\"\n",
    "    df = create_dataframe(directory)\n",
    "    locals()[df_name] = df\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 데이터프레임 출력 및 폴더 이름 출력\n",
    "for i, df in enumerate(dataframes):\n",
    "    folder_name = directories[i]\n",
    "    print(f\"Folder: {folder_name}\")\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369533c-a370-4dd4-be55-eb9641942340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401905c-313d-4041-acab-44942fa84956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns = df_1.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ad8afe1-f25d-4cfd-8644-f428546afe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n"
     ]
    }
   ],
   "source": [
    "# df_1(~df_1[\"epoch\"])\n",
    "print(df_1.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9720e15-ef8b-47c9-bd15-dd93f4fb8f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89871</td>\n",
       "      <td>0.95886</td>\n",
       "      <td>1.1810</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.73351</td>\n",
       "      <td>0.76658</td>\n",
       "      <td>0.57865</td>\n",
       "      <td>0.81670</td>\n",
       "      <td>1.00760</td>\n",
       "      <td>1.14230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.97987</td>\n",
       "      <td>0.98803</td>\n",
       "      <td>1.2168</td>\n",
       "      <td>0.85138</td>\n",
       "      <td>0.83251</td>\n",
       "      <td>0.87052</td>\n",
       "      <td>0.69120</td>\n",
       "      <td>0.72940</td>\n",
       "      <td>0.68469</td>\n",
       "      <td>1.08390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.96781</td>\n",
       "      <td>0.95245</td>\n",
       "      <td>1.2111</td>\n",
       "      <td>0.85414</td>\n",
       "      <td>0.81504</td>\n",
       "      <td>0.86918</td>\n",
       "      <td>0.67512</td>\n",
       "      <td>0.78431</td>\n",
       "      <td>0.73477</td>\n",
       "      <td>1.11560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.94518</td>\n",
       "      <td>0.91246</td>\n",
       "      <td>1.1957</td>\n",
       "      <td>0.86043</td>\n",
       "      <td>0.84120</td>\n",
       "      <td>0.88171</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.72953</td>\n",
       "      <td>0.68654</td>\n",
       "      <td>1.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90728</td>\n",
       "      <td>0.87481</td>\n",
       "      <td>1.1772</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.82450</td>\n",
       "      <td>0.86521</td>\n",
       "      <td>0.70788</td>\n",
       "      <td>0.68655</td>\n",
       "      <td>0.65895</td>\n",
       "      <td>1.07150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.87810</td>\n",
       "      <td>0.82732</td>\n",
       "      <td>1.1610</td>\n",
       "      <td>0.89106</td>\n",
       "      <td>0.84161</td>\n",
       "      <td>0.88911</td>\n",
       "      <td>0.73276</td>\n",
       "      <td>0.65941</td>\n",
       "      <td>0.57940</td>\n",
       "      <td>1.06410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.85686</td>\n",
       "      <td>0.80637</td>\n",
       "      <td>1.1506</td>\n",
       "      <td>0.88350</td>\n",
       "      <td>0.84658</td>\n",
       "      <td>0.88719</td>\n",
       "      <td>0.73376</td>\n",
       "      <td>0.63772</td>\n",
       "      <td>0.58078</td>\n",
       "      <td>1.04410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.84006</td>\n",
       "      <td>0.78498</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.88589</td>\n",
       "      <td>0.86392</td>\n",
       "      <td>0.89585</td>\n",
       "      <td>0.75284</td>\n",
       "      <td>0.59818</td>\n",
       "      <td>0.53761</td>\n",
       "      <td>1.02330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.82358</td>\n",
       "      <td>0.76334</td>\n",
       "      <td>1.1368</td>\n",
       "      <td>0.90431</td>\n",
       "      <td>0.84272</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.75933</td>\n",
       "      <td>0.59371</td>\n",
       "      <td>0.52786</td>\n",
       "      <td>1.01370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.80213</td>\n",
       "      <td>0.73779</td>\n",
       "      <td>1.1249</td>\n",
       "      <td>0.88994</td>\n",
       "      <td>0.86274</td>\n",
       "      <td>0.91052</td>\n",
       "      <td>0.76803</td>\n",
       "      <td>0.59082</td>\n",
       "      <td>0.50186</td>\n",
       "      <td>1.01800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.79180</td>\n",
       "      <td>0.72055</td>\n",
       "      <td>1.1183</td>\n",
       "      <td>0.88716</td>\n",
       "      <td>0.86078</td>\n",
       "      <td>0.90554</td>\n",
       "      <td>0.76616</td>\n",
       "      <td>0.57007</td>\n",
       "      <td>0.50717</td>\n",
       "      <td>1.01020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.77494</td>\n",
       "      <td>0.70086</td>\n",
       "      <td>1.1079</td>\n",
       "      <td>0.88809</td>\n",
       "      <td>0.85616</td>\n",
       "      <td>0.90711</td>\n",
       "      <td>0.77101</td>\n",
       "      <td>0.56238</td>\n",
       "      <td>0.50837</td>\n",
       "      <td>0.99873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.76201</td>\n",
       "      <td>0.68417</td>\n",
       "      <td>1.1039</td>\n",
       "      <td>0.88596</td>\n",
       "      <td>0.87778</td>\n",
       "      <td>0.91441</td>\n",
       "      <td>0.77737</td>\n",
       "      <td>0.56289</td>\n",
       "      <td>0.48083</td>\n",
       "      <td>1.00300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.74984</td>\n",
       "      <td>0.67548</td>\n",
       "      <td>1.0944</td>\n",
       "      <td>0.89994</td>\n",
       "      <td>0.85683</td>\n",
       "      <td>0.91100</td>\n",
       "      <td>0.77600</td>\n",
       "      <td>0.55184</td>\n",
       "      <td>0.48471</td>\n",
       "      <td>0.99550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.73398</td>\n",
       "      <td>0.65026</td>\n",
       "      <td>1.0876</td>\n",
       "      <td>0.91219</td>\n",
       "      <td>0.85377</td>\n",
       "      <td>0.91263</td>\n",
       "      <td>0.77853</td>\n",
       "      <td>0.55196</td>\n",
       "      <td>0.47646</td>\n",
       "      <td>1.00070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.72217</td>\n",
       "      <td>0.63458</td>\n",
       "      <td>1.0799</td>\n",
       "      <td>0.90204</td>\n",
       "      <td>0.86161</td>\n",
       "      <td>0.91403</td>\n",
       "      <td>0.78242</td>\n",
       "      <td>0.53595</td>\n",
       "      <td>0.47557</td>\n",
       "      <td>0.98911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.70481</td>\n",
       "      <td>0.61986</td>\n",
       "      <td>1.0738</td>\n",
       "      <td>0.90350</td>\n",
       "      <td>0.85855</td>\n",
       "      <td>0.91599</td>\n",
       "      <td>0.78249</td>\n",
       "      <td>0.53842</td>\n",
       "      <td>0.47370</td>\n",
       "      <td>0.99497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.69696</td>\n",
       "      <td>0.60523</td>\n",
       "      <td>1.0692</td>\n",
       "      <td>0.89539</td>\n",
       "      <td>0.87091</td>\n",
       "      <td>0.91336</td>\n",
       "      <td>0.77900</td>\n",
       "      <td>0.53673</td>\n",
       "      <td>0.47797</td>\n",
       "      <td>0.99229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.68686</td>\n",
       "      <td>0.58972</td>\n",
       "      <td>1.0632</td>\n",
       "      <td>0.90237</td>\n",
       "      <td>0.86136</td>\n",
       "      <td>0.91404</td>\n",
       "      <td>0.78047</td>\n",
       "      <td>0.53094</td>\n",
       "      <td>0.47586</td>\n",
       "      <td>0.99051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.67504</td>\n",
       "      <td>0.57737</td>\n",
       "      <td>1.0592</td>\n",
       "      <td>0.90532</td>\n",
       "      <td>0.85850</td>\n",
       "      <td>0.91386</td>\n",
       "      <td>0.78099</td>\n",
       "      <td>0.53665</td>\n",
       "      <td>0.48239</td>\n",
       "      <td>0.99481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train/box_loss  train/cls_loss  train/dfl_loss  metrics/precision(B)  \\\n",
       "0          0.89871         0.95886          1.1810               0.74300   \n",
       "1          0.97987         0.98803          1.2168               0.85138   \n",
       "2          0.96781         0.95245          1.2111               0.85414   \n",
       "3          0.94518         0.91246          1.1957               0.86043   \n",
       "4          0.90728         0.87481          1.1772               0.84712   \n",
       "5          0.87810         0.82732          1.1610               0.89106   \n",
       "6          0.85686         0.80637          1.1506               0.88350   \n",
       "7          0.84006         0.78498          1.1447               0.88589   \n",
       "8          0.82358         0.76334          1.1368               0.90431   \n",
       "9          0.80213         0.73779          1.1249               0.88994   \n",
       "10         0.79180         0.72055          1.1183               0.88716   \n",
       "11         0.77494         0.70086          1.1079               0.88809   \n",
       "12         0.76201         0.68417          1.1039               0.88596   \n",
       "13         0.74984         0.67548          1.0944               0.89994   \n",
       "14         0.73398         0.65026          1.0876               0.91219   \n",
       "15         0.72217         0.63458          1.0799               0.90204   \n",
       "16         0.70481         0.61986          1.0738               0.90350   \n",
       "17         0.69696         0.60523          1.0692               0.89539   \n",
       "18         0.68686         0.58972          1.0632               0.90237   \n",
       "19         0.67504         0.57737          1.0592               0.90532   \n",
       "\n",
       "    metrics/recall(B)  metrics/mAP50(B)  metrics/mAP50-95(B)  val/box_loss  \\\n",
       "0             0.73351           0.76658              0.57865       0.81670   \n",
       "1             0.83251           0.87052              0.69120       0.72940   \n",
       "2             0.81504           0.86918              0.67512       0.78431   \n",
       "3             0.84120           0.88171              0.69897       0.72953   \n",
       "4             0.82450           0.86521              0.70788       0.68655   \n",
       "5             0.84161           0.88911              0.73276       0.65941   \n",
       "6             0.84658           0.88719              0.73376       0.63772   \n",
       "7             0.86392           0.89585              0.75284       0.59818   \n",
       "8             0.84272           0.90322              0.75933       0.59371   \n",
       "9             0.86274           0.91052              0.76803       0.59082   \n",
       "10            0.86078           0.90554              0.76616       0.57007   \n",
       "11            0.85616           0.90711              0.77101       0.56238   \n",
       "12            0.87778           0.91441              0.77737       0.56289   \n",
       "13            0.85683           0.91100              0.77600       0.55184   \n",
       "14            0.85377           0.91263              0.77853       0.55196   \n",
       "15            0.86161           0.91403              0.78242       0.53595   \n",
       "16            0.85855           0.91599              0.78249       0.53842   \n",
       "17            0.87091           0.91336              0.77900       0.53673   \n",
       "18            0.86136           0.91404              0.78047       0.53094   \n",
       "19            0.85850           0.91386              0.78099       0.53665   \n",
       "\n",
       "    val/cls_loss  val/dfl_loss  \n",
       "0        1.00760       1.14230  \n",
       "1        0.68469       1.08390  \n",
       "2        0.73477       1.11560  \n",
       "3        0.68654       1.08020  \n",
       "4        0.65895       1.07150  \n",
       "5        0.57940       1.06410  \n",
       "6        0.58078       1.04410  \n",
       "7        0.53761       1.02330  \n",
       "8        0.52786       1.01370  \n",
       "9        0.50186       1.01800  \n",
       "10       0.50717       1.01020  \n",
       "11       0.50837       0.99873  \n",
       "12       0.48083       1.00300  \n",
       "13       0.48471       0.99550  \n",
       "14       0.47646       1.00070  \n",
       "15       0.47557       0.98911  \n",
       "16       0.47370       0.99497  \n",
       "17       0.47797       0.99229  \n",
       "18       0.47586       0.99051  \n",
       "19       0.48239       0.99481  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.iloc[:, 1:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58b45311-e24f-4b5f-b111-bf7a1a196473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c7d8da6a90>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_1.iloc[:, 1:-3])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a4b511-476e-474b-833b-e1d671e90146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.98252</td>\n",
       "      <td>1.83730</td>\n",
       "      <td>1.2435</td>\n",
       "      <td>0.79243</td>\n",
       "      <td>0.79363</td>\n",
       "      <td>0.83644</td>\n",
       "      <td>0.65564</td>\n",
       "      <td>0.69575</td>\n",
       "      <td>1.11280</td>\n",
       "      <td>1.08360</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.95776</td>\n",
       "      <td>1.17470</td>\n",
       "      <td>1.1999</td>\n",
       "      <td>0.82497</td>\n",
       "      <td>0.81294</td>\n",
       "      <td>0.85251</td>\n",
       "      <td>0.66818</td>\n",
       "      <td>0.73540</td>\n",
       "      <td>0.84830</td>\n",
       "      <td>1.09830</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>0.006443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.02630</td>\n",
       "      <td>1.12530</td>\n",
       "      <td>1.2401</td>\n",
       "      <td>0.74635</td>\n",
       "      <td>0.69058</td>\n",
       "      <td>0.74259</td>\n",
       "      <td>0.52071</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.26140</td>\n",
       "      <td>1.28180</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.009336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.05520</td>\n",
       "      <td>1.08990</td>\n",
       "      <td>1.2506</td>\n",
       "      <td>0.83196</td>\n",
       "      <td>0.79026</td>\n",
       "      <td>0.83457</td>\n",
       "      <td>0.63947</td>\n",
       "      <td>0.81101</td>\n",
       "      <td>0.78649</td>\n",
       "      <td>1.13790</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.99138</td>\n",
       "      <td>0.98886</td>\n",
       "      <td>1.2191</td>\n",
       "      <td>0.88281</td>\n",
       "      <td>0.82738</td>\n",
       "      <td>0.87618</td>\n",
       "      <td>0.70253</td>\n",
       "      <td>0.72257</td>\n",
       "      <td>0.66769</td>\n",
       "      <td>1.09100</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.95184</td>\n",
       "      <td>0.92604</td>\n",
       "      <td>1.1980</td>\n",
       "      <td>0.88356</td>\n",
       "      <td>0.84958</td>\n",
       "      <td>0.89613</td>\n",
       "      <td>0.72922</td>\n",
       "      <td>0.66736</td>\n",
       "      <td>0.59495</td>\n",
       "      <td>1.05630</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.008680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.92290</td>\n",
       "      <td>0.88459</td>\n",
       "      <td>1.1825</td>\n",
       "      <td>0.87861</td>\n",
       "      <td>0.82954</td>\n",
       "      <td>0.88788</td>\n",
       "      <td>0.71913</td>\n",
       "      <td>0.68893</td>\n",
       "      <td>0.63243</td>\n",
       "      <td>1.06740</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.008350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.90121</td>\n",
       "      <td>0.86108</td>\n",
       "      <td>1.1733</td>\n",
       "      <td>0.86992</td>\n",
       "      <td>0.86217</td>\n",
       "      <td>0.90068</td>\n",
       "      <td>0.74660</td>\n",
       "      <td>0.62789</td>\n",
       "      <td>0.56466</td>\n",
       "      <td>1.03940</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.008020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.88255</td>\n",
       "      <td>0.83060</td>\n",
       "      <td>1.1616</td>\n",
       "      <td>0.88595</td>\n",
       "      <td>0.85228</td>\n",
       "      <td>0.89965</td>\n",
       "      <td>0.74791</td>\n",
       "      <td>0.62686</td>\n",
       "      <td>0.56658</td>\n",
       "      <td>1.03170</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.007690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.80638</td>\n",
       "      <td>1.1502</td>\n",
       "      <td>0.88056</td>\n",
       "      <td>0.86310</td>\n",
       "      <td>0.90427</td>\n",
       "      <td>0.74871</td>\n",
       "      <td>0.63240</td>\n",
       "      <td>0.53715</td>\n",
       "      <td>1.03690</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.007360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.85153</td>\n",
       "      <td>0.79071</td>\n",
       "      <td>1.1445</td>\n",
       "      <td>0.87544</td>\n",
       "      <td>0.86223</td>\n",
       "      <td>0.90133</td>\n",
       "      <td>0.76174</td>\n",
       "      <td>0.58737</td>\n",
       "      <td>0.53037</td>\n",
       "      <td>1.01670</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.007030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.83636</td>\n",
       "      <td>0.77448</td>\n",
       "      <td>1.1355</td>\n",
       "      <td>0.87751</td>\n",
       "      <td>0.86178</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>0.75985</td>\n",
       "      <td>0.58624</td>\n",
       "      <td>0.53500</td>\n",
       "      <td>1.01500</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.81999</td>\n",
       "      <td>0.75839</td>\n",
       "      <td>1.1291</td>\n",
       "      <td>0.88558</td>\n",
       "      <td>0.86250</td>\n",
       "      <td>0.90378</td>\n",
       "      <td>0.76469</td>\n",
       "      <td>0.58051</td>\n",
       "      <td>0.51373</td>\n",
       "      <td>1.01300</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.006370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.80790</td>\n",
       "      <td>0.74601</td>\n",
       "      <td>1.1231</td>\n",
       "      <td>0.88651</td>\n",
       "      <td>0.86462</td>\n",
       "      <td>0.90722</td>\n",
       "      <td>0.77201</td>\n",
       "      <td>0.56991</td>\n",
       "      <td>0.50456</td>\n",
       "      <td>1.00580</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.79838</td>\n",
       "      <td>0.72310</td>\n",
       "      <td>1.1182</td>\n",
       "      <td>0.90203</td>\n",
       "      <td>0.85104</td>\n",
       "      <td>0.91202</td>\n",
       "      <td>0.77692</td>\n",
       "      <td>0.56345</td>\n",
       "      <td>0.48515</td>\n",
       "      <td>1.00200</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.005710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.78836</td>\n",
       "      <td>0.71055</td>\n",
       "      <td>1.1101</td>\n",
       "      <td>0.88638</td>\n",
       "      <td>0.86473</td>\n",
       "      <td>0.91074</td>\n",
       "      <td>0.77687</td>\n",
       "      <td>0.55344</td>\n",
       "      <td>0.48761</td>\n",
       "      <td>0.99785</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.77066</td>\n",
       "      <td>0.70166</td>\n",
       "      <td>1.1032</td>\n",
       "      <td>0.90235</td>\n",
       "      <td>0.86324</td>\n",
       "      <td>0.91690</td>\n",
       "      <td>0.77995</td>\n",
       "      <td>0.54888</td>\n",
       "      <td>0.47723</td>\n",
       "      <td>0.99398</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.76677</td>\n",
       "      <td>0.69116</td>\n",
       "      <td>1.1014</td>\n",
       "      <td>0.87690</td>\n",
       "      <td>0.88166</td>\n",
       "      <td>0.90846</td>\n",
       "      <td>0.77660</td>\n",
       "      <td>0.54097</td>\n",
       "      <td>0.48003</td>\n",
       "      <td>0.98922</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.75574</td>\n",
       "      <td>0.67589</td>\n",
       "      <td>1.0975</td>\n",
       "      <td>0.88234</td>\n",
       "      <td>0.86815</td>\n",
       "      <td>0.91074</td>\n",
       "      <td>0.77429</td>\n",
       "      <td>0.54072</td>\n",
       "      <td>0.47700</td>\n",
       "      <td>0.99617</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.004390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.74448</td>\n",
       "      <td>0.66252</td>\n",
       "      <td>1.0910</td>\n",
       "      <td>0.88857</td>\n",
       "      <td>0.87715</td>\n",
       "      <td>0.91741</td>\n",
       "      <td>0.78120</td>\n",
       "      <td>0.53785</td>\n",
       "      <td>0.46528</td>\n",
       "      <td>0.99044</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.73725</td>\n",
       "      <td>0.64624</td>\n",
       "      <td>1.0858</td>\n",
       "      <td>0.88426</td>\n",
       "      <td>0.88084</td>\n",
       "      <td>0.91525</td>\n",
       "      <td>0.77888</td>\n",
       "      <td>0.53504</td>\n",
       "      <td>0.47205</td>\n",
       "      <td>0.98893</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.72882</td>\n",
       "      <td>0.63383</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.90285</td>\n",
       "      <td>0.86838</td>\n",
       "      <td>0.91798</td>\n",
       "      <td>0.78196</td>\n",
       "      <td>0.53472</td>\n",
       "      <td>0.46907</td>\n",
       "      <td>0.98775</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.71630</td>\n",
       "      <td>0.62221</td>\n",
       "      <td>1.0760</td>\n",
       "      <td>0.90468</td>\n",
       "      <td>0.87134</td>\n",
       "      <td>0.91787</td>\n",
       "      <td>0.78202</td>\n",
       "      <td>0.52845</td>\n",
       "      <td>0.46943</td>\n",
       "      <td>0.98449</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.70318</td>\n",
       "      <td>0.60951</td>\n",
       "      <td>1.0685</td>\n",
       "      <td>0.89587</td>\n",
       "      <td>0.87328</td>\n",
       "      <td>0.91692</td>\n",
       "      <td>0.77833</td>\n",
       "      <td>0.53361</td>\n",
       "      <td>0.47216</td>\n",
       "      <td>0.98821</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.70155</td>\n",
       "      <td>0.60475</td>\n",
       "      <td>1.0680</td>\n",
       "      <td>0.89103</td>\n",
       "      <td>0.87804</td>\n",
       "      <td>0.91594</td>\n",
       "      <td>0.78104</td>\n",
       "      <td>0.52738</td>\n",
       "      <td>0.47456</td>\n",
       "      <td>0.98604</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.68812</td>\n",
       "      <td>0.59201</td>\n",
       "      <td>1.0614</td>\n",
       "      <td>0.90482</td>\n",
       "      <td>0.86956</td>\n",
       "      <td>0.91764</td>\n",
       "      <td>0.78245</td>\n",
       "      <td>0.52624</td>\n",
       "      <td>0.47106</td>\n",
       "      <td>0.98656</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.67781</td>\n",
       "      <td>0.57469</td>\n",
       "      <td>1.0563</td>\n",
       "      <td>0.89515</td>\n",
       "      <td>0.88066</td>\n",
       "      <td>0.92054</td>\n",
       "      <td>0.78124</td>\n",
       "      <td>0.52730</td>\n",
       "      <td>0.47175</td>\n",
       "      <td>0.98732</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.66846</td>\n",
       "      <td>0.56226</td>\n",
       "      <td>1.0514</td>\n",
       "      <td>0.89424</td>\n",
       "      <td>0.87515</td>\n",
       "      <td>0.91791</td>\n",
       "      <td>0.77881</td>\n",
       "      <td>0.53205</td>\n",
       "      <td>0.47796</td>\n",
       "      <td>0.99148</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.66006</td>\n",
       "      <td>0.54927</td>\n",
       "      <td>1.0486</td>\n",
       "      <td>0.89679</td>\n",
       "      <td>0.87398</td>\n",
       "      <td>0.91797</td>\n",
       "      <td>0.77722</td>\n",
       "      <td>0.53559</td>\n",
       "      <td>0.47957</td>\n",
       "      <td>0.99372</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.65114</td>\n",
       "      <td>0.53709</td>\n",
       "      <td>1.0430</td>\n",
       "      <td>0.89764</td>\n",
       "      <td>0.87507</td>\n",
       "      <td>0.91579</td>\n",
       "      <td>0.77465</td>\n",
       "      <td>0.53870</td>\n",
       "      <td>0.47819</td>\n",
       "      <td>0.99748</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      epoch           train/box_loss           train/cls_loss  \\\n",
       "0                         0                  0.98252                  1.83730   \n",
       "1                         1                  0.95776                  1.17470   \n",
       "2                         2                  1.02630                  1.12530   \n",
       "3                         3                  1.05520                  1.08990   \n",
       "4                         4                  0.99138                  0.98886   \n",
       "5                         5                  0.95184                  0.92604   \n",
       "6                         6                  0.92290                  0.88459   \n",
       "7                         7                  0.90121                  0.86108   \n",
       "8                         8                  0.88255                  0.83060   \n",
       "9                         9                  0.86180                  0.80638   \n",
       "10                       10                  0.85153                  0.79071   \n",
       "11                       11                  0.83636                  0.77448   \n",
       "12                       12                  0.81999                  0.75839   \n",
       "13                       13                  0.80790                  0.74601   \n",
       "14                       14                  0.79838                  0.72310   \n",
       "15                       15                  0.78836                  0.71055   \n",
       "16                       16                  0.77066                  0.70166   \n",
       "17                       17                  0.76677                  0.69116   \n",
       "18                       18                  0.75574                  0.67589   \n",
       "19                       19                  0.74448                  0.66252   \n",
       "20                       20                  0.73725                  0.64624   \n",
       "21                       21                  0.72882                  0.63383   \n",
       "22                       22                  0.71630                  0.62221   \n",
       "23                       23                  0.70318                  0.60951   \n",
       "24                       24                  0.70155                  0.60475   \n",
       "25                       25                  0.68812                  0.59201   \n",
       "26                       26                  0.67781                  0.57469   \n",
       "27                       27                  0.66846                  0.56226   \n",
       "28                       28                  0.66006                  0.54927   \n",
       "29                       29                  0.65114                  0.53709   \n",
       "\n",
       "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
       "0                    1.2435                  0.79243                  0.79363   \n",
       "1                    1.1999                  0.82497                  0.81294   \n",
       "2                    1.2401                  0.74635                  0.69058   \n",
       "3                    1.2506                  0.83196                  0.79026   \n",
       "4                    1.2191                  0.88281                  0.82738   \n",
       "5                    1.1980                  0.88356                  0.84958   \n",
       "6                    1.1825                  0.87861                  0.82954   \n",
       "7                    1.1733                  0.86992                  0.86217   \n",
       "8                    1.1616                  0.88595                  0.85228   \n",
       "9                    1.1502                  0.88056                  0.86310   \n",
       "10                   1.1445                  0.87544                  0.86223   \n",
       "11                   1.1355                  0.87751                  0.86178   \n",
       "12                   1.1291                  0.88558                  0.86250   \n",
       "13                   1.1231                  0.88651                  0.86462   \n",
       "14                   1.1182                  0.90203                  0.85104   \n",
       "15                   1.1101                  0.88638                  0.86473   \n",
       "16                   1.1032                  0.90235                  0.86324   \n",
       "17                   1.1014                  0.87690                  0.88166   \n",
       "18                   1.0975                  0.88234                  0.86815   \n",
       "19                   1.0910                  0.88857                  0.87715   \n",
       "20                   1.0858                  0.88426                  0.88084   \n",
       "21                   1.0830                  0.90285                  0.86838   \n",
       "22                   1.0760                  0.90468                  0.87134   \n",
       "23                   1.0685                  0.89587                  0.87328   \n",
       "24                   1.0680                  0.89103                  0.87804   \n",
       "25                   1.0614                  0.90482                  0.86956   \n",
       "26                   1.0563                  0.89515                  0.88066   \n",
       "27                   1.0514                  0.89424                  0.87515   \n",
       "28                   1.0486                  0.89679                  0.87398   \n",
       "29                   1.0430                  0.89764                  0.87507   \n",
       "\n",
       "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
       "0                   0.83644                  0.65564                  0.69575   \n",
       "1                   0.85251                  0.66818                  0.73540   \n",
       "2                   0.74259                  0.52071                  1.03720   \n",
       "3                   0.83457                  0.63947                  0.81101   \n",
       "4                   0.87618                  0.70253                  0.72257   \n",
       "5                   0.89613                  0.72922                  0.66736   \n",
       "6                   0.88788                  0.71913                  0.68893   \n",
       "7                   0.90068                  0.74660                  0.62789   \n",
       "8                   0.89965                  0.74791                  0.62686   \n",
       "9                   0.90427                  0.74871                  0.63240   \n",
       "10                  0.90133                  0.76174                  0.58737   \n",
       "11                  0.89815                  0.75985                  0.58624   \n",
       "12                  0.90378                  0.76469                  0.58051   \n",
       "13                  0.90722                  0.77201                  0.56991   \n",
       "14                  0.91202                  0.77692                  0.56345   \n",
       "15                  0.91074                  0.77687                  0.55344   \n",
       "16                  0.91690                  0.77995                  0.54888   \n",
       "17                  0.90846                  0.77660                  0.54097   \n",
       "18                  0.91074                  0.77429                  0.54072   \n",
       "19                  0.91741                  0.78120                  0.53785   \n",
       "20                  0.91525                  0.77888                  0.53504   \n",
       "21                  0.91798                  0.78196                  0.53472   \n",
       "22                  0.91787                  0.78202                  0.52845   \n",
       "23                  0.91692                  0.77833                  0.53361   \n",
       "24                  0.91594                  0.78104                  0.52738   \n",
       "25                  0.91764                  0.78245                  0.52624   \n",
       "26                  0.92054                  0.78124                  0.52730   \n",
       "27                  0.91791                  0.77881                  0.53205   \n",
       "28                  0.91797                  0.77722                  0.53559   \n",
       "29                  0.91579                  0.77465                  0.53870   \n",
       "\n",
       "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                   1.11280                  1.08360                 0.003329   \n",
       "1                   0.84830                  1.09830                 0.006443   \n",
       "2                   1.26140                  1.28180                 0.009336   \n",
       "3                   0.78649                  1.13790                 0.009010   \n",
       "4                   0.66769                  1.09100                 0.009010   \n",
       "5                   0.59495                  1.05630                 0.008680   \n",
       "6                   0.63243                  1.06740                 0.008350   \n",
       "7                   0.56466                  1.03940                 0.008020   \n",
       "8                   0.56658                  1.03170                 0.007690   \n",
       "9                   0.53715                  1.03690                 0.007360   \n",
       "10                  0.53037                  1.01670                 0.007030   \n",
       "11                  0.53500                  1.01500                 0.006700   \n",
       "12                  0.51373                  1.01300                 0.006370   \n",
       "13                  0.50456                  1.00580                 0.006040   \n",
       "14                  0.48515                  1.00200                 0.005710   \n",
       "15                  0.48761                  0.99785                 0.005380   \n",
       "16                  0.47723                  0.99398                 0.005050   \n",
       "17                  0.48003                  0.98922                 0.004720   \n",
       "18                  0.47700                  0.99617                 0.004390   \n",
       "19                  0.46528                  0.99044                 0.004060   \n",
       "20                  0.47205                  0.98893                 0.003730   \n",
       "21                  0.46907                  0.98775                 0.003400   \n",
       "22                  0.46943                  0.98449                 0.003070   \n",
       "23                  0.47216                  0.98821                 0.002740   \n",
       "24                  0.47456                  0.98604                 0.002410   \n",
       "25                  0.47106                  0.98656                 0.002080   \n",
       "26                  0.47175                  0.98732                 0.001750   \n",
       "27                  0.47796                  0.99148                 0.001420   \n",
       "28                  0.47957                  0.99372                 0.001090   \n",
       "29                  0.47819                  0.99748                 0.000760   \n",
       "\n",
       "                     lr/pg1                   lr/pg2  \n",
       "0                  0.003329                 0.003329  \n",
       "1                  0.006443                 0.006443  \n",
       "2                  0.009336                 0.009336  \n",
       "3                  0.009010                 0.009010  \n",
       "4                  0.009010                 0.009010  \n",
       "5                  0.008680                 0.008680  \n",
       "6                  0.008350                 0.008350  \n",
       "7                  0.008020                 0.008020  \n",
       "8                  0.007690                 0.007690  \n",
       "9                  0.007360                 0.007360  \n",
       "10                 0.007030                 0.007030  \n",
       "11                 0.006700                 0.006700  \n",
       "12                 0.006370                 0.006370  \n",
       "13                 0.006040                 0.006040  \n",
       "14                 0.005710                 0.005710  \n",
       "15                 0.005380                 0.005380  \n",
       "16                 0.005050                 0.005050  \n",
       "17                 0.004720                 0.004720  \n",
       "18                 0.004390                 0.004390  \n",
       "19                 0.004060                 0.004060  \n",
       "20                 0.003730                 0.003730  \n",
       "21                 0.003400                 0.003400  \n",
       "22                 0.003070                 0.003070  \n",
       "23                 0.002740                 0.002740  \n",
       "24                 0.002410                 0.002410  \n",
       "25                 0.002080                 0.002080  \n",
       "26                 0.001750                 0.001750  \n",
       "27                 0.001420                 0.001420  \n",
       "28                 0.001090                 0.001090  \n",
       "29                 0.000760                 0.000760  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bbd87c-b475-4629-a6c4-8b01cace9f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00380</td>\n",
       "      <td>1.48350</td>\n",
       "      <td>1.2499</td>\n",
       "      <td>0.72632</td>\n",
       "      <td>0.76036</td>\n",
       "      <td>0.76198</td>\n",
       "      <td>0.57244</td>\n",
       "      <td>0.79767</td>\n",
       "      <td>1.13170</td>\n",
       "      <td>1.1318</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94826</td>\n",
       "      <td>0.99781</td>\n",
       "      <td>1.2048</td>\n",
       "      <td>0.78734</td>\n",
       "      <td>0.82355</td>\n",
       "      <td>0.85151</td>\n",
       "      <td>0.67836</td>\n",
       "      <td>0.70087</td>\n",
       "      <td>0.77589</td>\n",
       "      <td>1.0744</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.87608</td>\n",
       "      <td>0.87002</td>\n",
       "      <td>1.1684</td>\n",
       "      <td>0.85647</td>\n",
       "      <td>0.83541</td>\n",
       "      <td>0.87208</td>\n",
       "      <td>0.71021</td>\n",
       "      <td>0.66615</td>\n",
       "      <td>0.65397</td>\n",
       "      <td>1.0513</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     epoch           train/box_loss           train/cls_loss  \\\n",
       "0                        0                  1.00380                  1.48350   \n",
       "1                        1                  0.94826                  0.99781   \n",
       "2                        2                  0.87608                  0.87002   \n",
       "\n",
       "            train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
       "0                   1.2499                  0.72632                  0.76036   \n",
       "1                   1.2048                  0.78734                  0.82355   \n",
       "2                   1.1684                  0.85647                  0.83541   \n",
       "\n",
       "          metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
       "0                  0.76198                  0.57244                  0.79767   \n",
       "1                  0.85151                  0.67836                  0.70087   \n",
       "2                  0.87208                  0.71021                  0.66615   \n",
       "\n",
       "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                  1.13170                   1.1318                 0.000476   \n",
       "1                  0.77589                   1.0744                 0.000638   \n",
       "2                  0.65397                   1.0513                 0.000486   \n",
       "\n",
       "                    lr/pg1                   lr/pg2  \n",
       "0                 0.000476                 0.000476  \n",
       "1                 0.000638                 0.000638  \n",
       "2                 0.000486                 0.000486  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53657f5-6a73-4b4c-bc99-e75464bfcad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.96490</td>\n",
       "      <td>1.82840</td>\n",
       "      <td>1.23500</td>\n",
       "      <td>0.83749</td>\n",
       "      <td>0.77292</td>\n",
       "      <td>0.82800</td>\n",
       "      <td>0.65284</td>\n",
       "      <td>0.78202</td>\n",
       "      <td>1.19380</td>\n",
       "      <td>1.10840</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94748</td>\n",
       "      <td>1.14970</td>\n",
       "      <td>1.19450</td>\n",
       "      <td>0.80467</td>\n",
       "      <td>0.76979</td>\n",
       "      <td>0.83327</td>\n",
       "      <td>0.64360</td>\n",
       "      <td>0.83286</td>\n",
       "      <td>1.02930</td>\n",
       "      <td>1.15860</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.006596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.01220</td>\n",
       "      <td>1.11530</td>\n",
       "      <td>1.23310</td>\n",
       "      <td>0.80015</td>\n",
       "      <td>0.76479</td>\n",
       "      <td>0.81192</td>\n",
       "      <td>0.58288</td>\n",
       "      <td>0.98705</td>\n",
       "      <td>1.02940</td>\n",
       "      <td>1.25700</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.009798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.05020</td>\n",
       "      <td>1.07890</td>\n",
       "      <td>1.25550</td>\n",
       "      <td>0.83126</td>\n",
       "      <td>0.79041</td>\n",
       "      <td>0.85077</td>\n",
       "      <td>0.66129</td>\n",
       "      <td>0.85244</td>\n",
       "      <td>0.83846</td>\n",
       "      <td>1.16170</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.99577</td>\n",
       "      <td>0.98411</td>\n",
       "      <td>1.22530</td>\n",
       "      <td>0.84411</td>\n",
       "      <td>0.80570</td>\n",
       "      <td>0.86557</td>\n",
       "      <td>0.67738</td>\n",
       "      <td>0.82725</td>\n",
       "      <td>0.77935</td>\n",
       "      <td>1.14950</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.54197</td>\n",
       "      <td>0.39140</td>\n",
       "      <td>0.97786</td>\n",
       "      <td>0.97318</td>\n",
       "      <td>0.96252</td>\n",
       "      <td>0.98715</td>\n",
       "      <td>0.92328</td>\n",
       "      <td>0.38608</td>\n",
       "      <td>0.24251</td>\n",
       "      <td>0.86558</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.54501</td>\n",
       "      <td>0.38888</td>\n",
       "      <td>0.97986</td>\n",
       "      <td>0.97305</td>\n",
       "      <td>0.96214</td>\n",
       "      <td>0.98747</td>\n",
       "      <td>0.92414</td>\n",
       "      <td>0.38386</td>\n",
       "      <td>0.24020</td>\n",
       "      <td>0.86411</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.53806</td>\n",
       "      <td>0.38464</td>\n",
       "      <td>0.97584</td>\n",
       "      <td>0.97383</td>\n",
       "      <td>0.96097</td>\n",
       "      <td>0.98766</td>\n",
       "      <td>0.92505</td>\n",
       "      <td>0.38215</td>\n",
       "      <td>0.23822</td>\n",
       "      <td>0.86320</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.53366</td>\n",
       "      <td>0.37925</td>\n",
       "      <td>0.97642</td>\n",
       "      <td>0.97300</td>\n",
       "      <td>0.96141</td>\n",
       "      <td>0.98788</td>\n",
       "      <td>0.92608</td>\n",
       "      <td>0.38012</td>\n",
       "      <td>0.23612</td>\n",
       "      <td>0.86199</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.53853</td>\n",
       "      <td>0.38273</td>\n",
       "      <td>0.97732</td>\n",
       "      <td>0.97455</td>\n",
       "      <td>0.96027</td>\n",
       "      <td>0.98806</td>\n",
       "      <td>0.92686</td>\n",
       "      <td>0.37857</td>\n",
       "      <td>0.23451</td>\n",
       "      <td>0.86084</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      epoch           train/box_loss           train/cls_loss  \\\n",
       "0                         0                  0.96490                  1.82840   \n",
       "1                         1                  0.94748                  1.14970   \n",
       "2                         2                  1.01220                  1.11530   \n",
       "3                         3                  1.05020                  1.07890   \n",
       "4                         4                  0.99577                  0.98411   \n",
       "..                      ...                      ...                      ...   \n",
       "95                       95                  0.54197                  0.39140   \n",
       "96                       96                  0.54501                  0.38888   \n",
       "97                       97                  0.53806                  0.38464   \n",
       "98                       98                  0.53366                  0.37925   \n",
       "99                       99                  0.53853                  0.38273   \n",
       "\n",
       "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
       "0                   1.23500                  0.83749                  0.77292   \n",
       "1                   1.19450                  0.80467                  0.76979   \n",
       "2                   1.23310                  0.80015                  0.76479   \n",
       "3                   1.25550                  0.83126                  0.79041   \n",
       "4                   1.22530                  0.84411                  0.80570   \n",
       "..                      ...                      ...                      ...   \n",
       "95                  0.97786                  0.97318                  0.96252   \n",
       "96                  0.97986                  0.97305                  0.96214   \n",
       "97                  0.97584                  0.97383                  0.96097   \n",
       "98                  0.97642                  0.97300                  0.96141   \n",
       "99                  0.97732                  0.97455                  0.96027   \n",
       "\n",
       "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
       "0                   0.82800                  0.65284                  0.78202   \n",
       "1                   0.83327                  0.64360                  0.83286   \n",
       "2                   0.81192                  0.58288                  0.98705   \n",
       "3                   0.85077                  0.66129                  0.85244   \n",
       "4                   0.86557                  0.67738                  0.82725   \n",
       "..                      ...                      ...                      ...   \n",
       "95                  0.98715                  0.92328                  0.38608   \n",
       "96                  0.98747                  0.92414                  0.38386   \n",
       "97                  0.98766                  0.92505                  0.38215   \n",
       "98                  0.98788                  0.92608                  0.38012   \n",
       "99                  0.98806                  0.92686                  0.37857   \n",
       "\n",
       "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                   1.19380                  1.10840                 0.003329   \n",
       "1                   1.02930                  1.15860                 0.006596   \n",
       "2                   1.02940                  1.25700                 0.009798   \n",
       "3                   0.83846                  1.16170                 0.009703   \n",
       "4                   0.77935                  1.14950                 0.009703   \n",
       "..                      ...                      ...                      ...   \n",
       "95                  0.24251                  0.86558                 0.000694   \n",
       "96                  0.24020                  0.86411                 0.000595   \n",
       "97                  0.23822                  0.86320                 0.000496   \n",
       "98                  0.23612                  0.86199                 0.000397   \n",
       "99                  0.23451                  0.86084                 0.000298   \n",
       "\n",
       "                     lr/pg1                   lr/pg2  \n",
       "0                  0.003329                 0.003329  \n",
       "1                  0.006596                 0.006596  \n",
       "2                  0.009798                 0.009798  \n",
       "3                  0.009703                 0.009703  \n",
       "4                  0.009703                 0.009703  \n",
       "..                      ...                      ...  \n",
       "95                 0.000694                 0.000694  \n",
       "96                 0.000595                 0.000595  \n",
       "97                 0.000496                 0.000496  \n",
       "98                 0.000397                 0.000397  \n",
       "99                 0.000298                 0.000298  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101cc4d8-2a25-4abe-8212-799709fe1a72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.96287</td>\n",
       "      <td>2.40580</td>\n",
       "      <td>1.23900</td>\n",
       "      <td>0.45047</td>\n",
       "      <td>0.59132</td>\n",
       "      <td>0.46534</td>\n",
       "      <td>0.36322</td>\n",
       "      <td>0.76364</td>\n",
       "      <td>1.51310</td>\n",
       "      <td>1.09650</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94700</td>\n",
       "      <td>1.60650</td>\n",
       "      <td>1.19300</td>\n",
       "      <td>0.47858</td>\n",
       "      <td>0.56141</td>\n",
       "      <td>0.46444</td>\n",
       "      <td>0.35407</td>\n",
       "      <td>0.83660</td>\n",
       "      <td>1.47340</td>\n",
       "      <td>1.14950</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.006596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.01270</td>\n",
       "      <td>1.54330</td>\n",
       "      <td>1.22620</td>\n",
       "      <td>0.31162</td>\n",
       "      <td>0.46589</td>\n",
       "      <td>0.37150</td>\n",
       "      <td>0.26155</td>\n",
       "      <td>1.00810</td>\n",
       "      <td>1.76260</td>\n",
       "      <td>1.25950</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.009798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.05150</td>\n",
       "      <td>1.46920</td>\n",
       "      <td>1.24450</td>\n",
       "      <td>0.27638</td>\n",
       "      <td>0.48210</td>\n",
       "      <td>0.24554</td>\n",
       "      <td>0.17570</td>\n",
       "      <td>0.97235</td>\n",
       "      <td>2.31800</td>\n",
       "      <td>1.22760</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>1.35250</td>\n",
       "      <td>1.21370</td>\n",
       "      <td>0.50370</td>\n",
       "      <td>0.57183</td>\n",
       "      <td>0.48623</td>\n",
       "      <td>0.37072</td>\n",
       "      <td>0.84057</td>\n",
       "      <td>1.30490</td>\n",
       "      <td>1.15100</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.52903</td>\n",
       "      <td>0.44878</td>\n",
       "      <td>0.96449</td>\n",
       "      <td>0.97360</td>\n",
       "      <td>0.95880</td>\n",
       "      <td>0.98750</td>\n",
       "      <td>0.92009</td>\n",
       "      <td>0.35064</td>\n",
       "      <td>0.23651</td>\n",
       "      <td>0.83986</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>0.44552</td>\n",
       "      <td>0.96516</td>\n",
       "      <td>0.97366</td>\n",
       "      <td>0.95948</td>\n",
       "      <td>0.98790</td>\n",
       "      <td>0.92079</td>\n",
       "      <td>0.34895</td>\n",
       "      <td>0.23413</td>\n",
       "      <td>0.83873</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.52355</td>\n",
       "      <td>0.43810</td>\n",
       "      <td>0.96227</td>\n",
       "      <td>0.97403</td>\n",
       "      <td>0.96118</td>\n",
       "      <td>0.98824</td>\n",
       "      <td>0.92193</td>\n",
       "      <td>0.34728</td>\n",
       "      <td>0.23219</td>\n",
       "      <td>0.83769</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.51882</td>\n",
       "      <td>0.43133</td>\n",
       "      <td>0.96278</td>\n",
       "      <td>0.97433</td>\n",
       "      <td>0.96085</td>\n",
       "      <td>0.98858</td>\n",
       "      <td>0.92308</td>\n",
       "      <td>0.34596</td>\n",
       "      <td>0.23054</td>\n",
       "      <td>0.83696</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.52139</td>\n",
       "      <td>0.43602</td>\n",
       "      <td>0.96346</td>\n",
       "      <td>0.97430</td>\n",
       "      <td>0.96098</td>\n",
       "      <td>0.98883</td>\n",
       "      <td>0.92437</td>\n",
       "      <td>0.34446</td>\n",
       "      <td>0.22880</td>\n",
       "      <td>0.83603</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      epoch           train/box_loss           train/cls_loss  \\\n",
       "0                         0                  0.96287                  2.40580   \n",
       "1                         1                  0.94700                  1.60650   \n",
       "2                         2                  1.01270                  1.54330   \n",
       "3                         3                  1.05150                  1.46920   \n",
       "4                         4                  0.99516                  1.35250   \n",
       "..                      ...                      ...                      ...   \n",
       "95                       95                  0.52903                  0.44878   \n",
       "96                       96                  0.52798                  0.44552   \n",
       "97                       97                  0.52355                  0.43810   \n",
       "98                       98                  0.51882                  0.43133   \n",
       "99                       99                  0.52139                  0.43602   \n",
       "\n",
       "             train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
       "0                   1.23900                  0.45047                  0.59132   \n",
       "1                   1.19300                  0.47858                  0.56141   \n",
       "2                   1.22620                  0.31162                  0.46589   \n",
       "3                   1.24450                  0.27638                  0.48210   \n",
       "4                   1.21370                  0.50370                  0.57183   \n",
       "..                      ...                      ...                      ...   \n",
       "95                  0.96449                  0.97360                  0.95880   \n",
       "96                  0.96516                  0.97366                  0.95948   \n",
       "97                  0.96227                  0.97403                  0.96118   \n",
       "98                  0.96278                  0.97433                  0.96085   \n",
       "99                  0.96346                  0.97430                  0.96098   \n",
       "\n",
       "           metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
       "0                   0.46534                  0.36322                  0.76364   \n",
       "1                   0.46444                  0.35407                  0.83660   \n",
       "2                   0.37150                  0.26155                  1.00810   \n",
       "3                   0.24554                  0.17570                  0.97235   \n",
       "4                   0.48623                  0.37072                  0.84057   \n",
       "..                      ...                      ...                      ...   \n",
       "95                  0.98750                  0.92009                  0.35064   \n",
       "96                  0.98790                  0.92079                  0.34895   \n",
       "97                  0.98824                  0.92193                  0.34728   \n",
       "98                  0.98858                  0.92308                  0.34596   \n",
       "99                  0.98883                  0.92437                  0.34446   \n",
       "\n",
       "               val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                   1.51310                  1.09650                 0.003329   \n",
       "1                   1.47340                  1.14950                 0.006596   \n",
       "2                   1.76260                  1.25950                 0.009798   \n",
       "3                   2.31800                  1.22760                 0.009703   \n",
       "4                   1.30490                  1.15100                 0.009703   \n",
       "..                      ...                      ...                      ...   \n",
       "95                  0.23651                  0.83986                 0.000694   \n",
       "96                  0.23413                  0.83873                 0.000595   \n",
       "97                  0.23219                  0.83769                 0.000496   \n",
       "98                  0.23054                  0.83696                 0.000397   \n",
       "99                  0.22880                  0.83603                 0.000298   \n",
       "\n",
       "                     lr/pg1                   lr/pg2  \n",
       "0                  0.003329                 0.003329  \n",
       "1                  0.006596                 0.006596  \n",
       "2                  0.009798                 0.009798  \n",
       "3                  0.009703                 0.009703  \n",
       "4                  0.009703                 0.009703  \n",
       "..                      ...                      ...  \n",
       "95                 0.000694                 0.000694  \n",
       "96                 0.000595                 0.000595  \n",
       "97                 0.000496                 0.000496  \n",
       "98                 0.000397                 0.000397  \n",
       "99                 0.000298                 0.000298  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9826f8fc-48c3-4320-9c16-642eeb35b65c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.77882</td>\n",
       "      <td>1.32780</td>\n",
       "      <td>1.1460</td>\n",
       "      <td>0.45303</td>\n",
       "      <td>0.47637</td>\n",
       "      <td>0.43280</td>\n",
       "      <td>0.28655</td>\n",
       "      <td>1.3955</td>\n",
       "      <td>1.8049</td>\n",
       "      <td>1.6499</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.76652</td>\n",
       "      <td>0.84595</td>\n",
       "      <td>1.1188</td>\n",
       "      <td>0.49370</td>\n",
       "      <td>0.42200</td>\n",
       "      <td>0.39920</td>\n",
       "      <td>0.27556</td>\n",
       "      <td>1.8212</td>\n",
       "      <td>1.8842</td>\n",
       "      <td>2.1610</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75293</td>\n",
       "      <td>0.76196</td>\n",
       "      <td>1.1135</td>\n",
       "      <td>0.71817</td>\n",
       "      <td>0.59211</td>\n",
       "      <td>0.64548</td>\n",
       "      <td>0.44363</td>\n",
       "      <td>1.5452</td>\n",
       "      <td>1.3345</td>\n",
       "      <td>1.7338</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.71320</td>\n",
       "      <td>0.68739</td>\n",
       "      <td>1.0969</td>\n",
       "      <td>0.81722</td>\n",
       "      <td>0.52973</td>\n",
       "      <td>0.63623</td>\n",
       "      <td>0.45125</td>\n",
       "      <td>1.4919</td>\n",
       "      <td>1.6075</td>\n",
       "      <td>1.6947</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.68329</td>\n",
       "      <td>0.65914</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.78871</td>\n",
       "      <td>0.63686</td>\n",
       "      <td>0.71095</td>\n",
       "      <td>0.49683</td>\n",
       "      <td>1.3807</td>\n",
       "      <td>1.2084</td>\n",
       "      <td>1.6083</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.62639</td>\n",
       "      <td>0.59493</td>\n",
       "      <td>1.0592</td>\n",
       "      <td>0.79189</td>\n",
       "      <td>0.70259</td>\n",
       "      <td>0.78663</td>\n",
       "      <td>0.56061</td>\n",
       "      <td>1.2879</td>\n",
       "      <td>1.0586</td>\n",
       "      <td>1.4940</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     epoch           train/box_loss           train/cls_loss  \\\n",
       "0                        0                  0.77882                  1.32780   \n",
       "1                        1                  0.76652                  0.84595   \n",
       "2                        2                  0.75293                  0.76196   \n",
       "3                        3                  0.71320                  0.68739   \n",
       "4                        4                  0.68329                  0.65914   \n",
       "5                        5                  0.62639                  0.59493   \n",
       "\n",
       "            train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
       "0                   1.1460                  0.45303                  0.47637   \n",
       "1                   1.1188                  0.49370                  0.42200   \n",
       "2                   1.1135                  0.71817                  0.59211   \n",
       "3                   1.0969                  0.81722                  0.52973   \n",
       "4                   1.0845                  0.78871                  0.63686   \n",
       "5                   1.0592                  0.79189                  0.70259   \n",
       "\n",
       "          metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
       "0                  0.43280                  0.28655                   1.3955   \n",
       "1                  0.39920                  0.27556                   1.8212   \n",
       "2                  0.64548                  0.44363                   1.5452   \n",
       "3                  0.63623                  0.45125                   1.4919   \n",
       "4                  0.71095                  0.49683                   1.3807   \n",
       "5                  0.78663                  0.56061                   1.2879   \n",
       "\n",
       "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                   1.8049                   1.6499                 0.000553   \n",
       "1                   1.8842                   2.1610                 0.000926   \n",
       "2                   1.3345                   1.7338                 0.001115   \n",
       "3                   1.6075                   1.6947                 0.000842   \n",
       "4                   1.2084                   1.6083                 0.000842   \n",
       "5                   1.0586                   1.4940                 0.000567   \n",
       "\n",
       "                    lr/pg1                   lr/pg2  \n",
       "0                 0.000553                 0.000553  \n",
       "1                 0.000926                 0.000926  \n",
       "2                 0.001115                 0.001115  \n",
       "3                 0.000842                 0.000842  \n",
       "4                 0.000842                 0.000842  \n",
       "5                 0.000567                 0.000567  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52395b22-636f-4184-904c-1259882aa23b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00430</td>\n",
       "      <td>1.47530</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>0.70252</td>\n",
       "      <td>0.67392</td>\n",
       "      <td>0.71140</td>\n",
       "      <td>0.53011</td>\n",
       "      <td>0.82528</td>\n",
       "      <td>1.36180</td>\n",
       "      <td>1.1450</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99014</td>\n",
       "      <td>1.03430</td>\n",
       "      <td>1.2254</td>\n",
       "      <td>0.79881</td>\n",
       "      <td>0.81797</td>\n",
       "      <td>0.83192</td>\n",
       "      <td>0.64776</td>\n",
       "      <td>0.78122</td>\n",
       "      <td>0.76913</td>\n",
       "      <td>1.1085</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.95486</td>\n",
       "      <td>0.95224</td>\n",
       "      <td>1.2051</td>\n",
       "      <td>0.83734</td>\n",
       "      <td>0.82623</td>\n",
       "      <td>0.84643</td>\n",
       "      <td>0.67018</td>\n",
       "      <td>0.75950</td>\n",
       "      <td>0.75705</td>\n",
       "      <td>1.0940</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.91880</td>\n",
       "      <td>0.89117</td>\n",
       "      <td>1.1860</td>\n",
       "      <td>0.86206</td>\n",
       "      <td>0.82121</td>\n",
       "      <td>0.88074</td>\n",
       "      <td>0.72244</td>\n",
       "      <td>0.65868</td>\n",
       "      <td>0.63894</td>\n",
       "      <td>1.0558</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.89151</td>\n",
       "      <td>0.85509</td>\n",
       "      <td>1.1708</td>\n",
       "      <td>0.85839</td>\n",
       "      <td>0.83001</td>\n",
       "      <td>0.87744</td>\n",
       "      <td>0.72071</td>\n",
       "      <td>0.66564</td>\n",
       "      <td>0.65624</td>\n",
       "      <td>1.0528</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.84672</td>\n",
       "      <td>0.80102</td>\n",
       "      <td>1.1506</td>\n",
       "      <td>0.88506</td>\n",
       "      <td>0.85606</td>\n",
       "      <td>0.89896</td>\n",
       "      <td>0.74618</td>\n",
       "      <td>0.61636</td>\n",
       "      <td>0.55284</td>\n",
       "      <td>1.0278</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.81423</td>\n",
       "      <td>0.75268</td>\n",
       "      <td>1.1376</td>\n",
       "      <td>0.88256</td>\n",
       "      <td>0.85943</td>\n",
       "      <td>0.89949</td>\n",
       "      <td>0.75760</td>\n",
       "      <td>0.59784</td>\n",
       "      <td>0.54363</td>\n",
       "      <td>1.0256</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.77222</td>\n",
       "      <td>0.70639</td>\n",
       "      <td>1.1147</td>\n",
       "      <td>0.88131</td>\n",
       "      <td>0.87326</td>\n",
       "      <td>0.90676</td>\n",
       "      <td>0.76167</td>\n",
       "      <td>0.57547</td>\n",
       "      <td>0.51395</td>\n",
       "      <td>1.0162</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     epoch           train/box_loss           train/cls_loss  \\\n",
       "0                        0                  1.00430                  1.47530   \n",
       "1                        1                  0.99014                  1.03430   \n",
       "2                        2                  0.95486                  0.95224   \n",
       "3                        3                  0.91880                  0.89117   \n",
       "4                        4                  0.89151                  0.85509   \n",
       "5                        5                  0.84672                  0.80102   \n",
       "6                        6                  0.81423                  0.75268   \n",
       "7                        7                  0.77222                  0.70639   \n",
       "\n",
       "            train/dfl_loss     metrics/precision(B)        metrics/recall(B)  \\\n",
       "0                   1.2500                  0.70252                  0.67392   \n",
       "1                   1.2254                  0.79881                  0.81797   \n",
       "2                   1.2051                  0.83734                  0.82623   \n",
       "3                   1.1860                  0.86206                  0.82121   \n",
       "4                   1.1708                  0.85839                  0.83001   \n",
       "5                   1.1506                  0.88506                  0.85606   \n",
       "6                   1.1376                  0.88256                  0.85943   \n",
       "7                   1.1147                  0.88131                  0.87326   \n",
       "\n",
       "          metrics/mAP50(B)      metrics/mAP50-95(B)             val/box_loss  \\\n",
       "0                  0.71140                  0.53011                  0.82528   \n",
       "1                  0.83192                  0.64776                  0.78122   \n",
       "2                  0.84643                  0.67018                  0.75950   \n",
       "3                  0.88074                  0.72244                  0.65868   \n",
       "4                  0.87744                  0.72071                  0.66564   \n",
       "5                  0.89896                  0.74618                  0.61636   \n",
       "6                  0.89949                  0.75760                  0.59784   \n",
       "7                  0.90676                  0.76167                  0.57547   \n",
       "\n",
       "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                  1.36180                   1.1450                 0.000476   \n",
       "1                  0.76913                   1.1085                 0.000834   \n",
       "2                  0.75705                   1.0940                 0.001075   \n",
       "3                  0.63894                   1.0558                 0.000898   \n",
       "4                  0.65624                   1.0528                 0.000898   \n",
       "5                  0.55284                   1.0278                 0.000722   \n",
       "6                  0.54363                   1.0256                 0.000545   \n",
       "7                  0.51395                   1.0162                 0.000368   \n",
       "\n",
       "                    lr/pg1                   lr/pg2  \n",
       "0                 0.000476                 0.000476  \n",
       "1                 0.000834                 0.000834  \n",
       "2                 0.001075                 0.001075  \n",
       "3                 0.000898                 0.000898  \n",
       "4                 0.000898                 0.000898  \n",
       "5                 0.000722                 0.000722  \n",
       "6                 0.000545                 0.000545  \n",
       "7                 0.000368                 0.000368  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999399f3-7ec5-4d24-a0ab-ffb795cda7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d102eb-bf75-4790-8e16-cea3ead5b901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a208ce-91ac-4716-8730-e8db7b27909d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959e88c-bb43-432a-9a47-78a5eeb8177c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88215470-f440-41c9-9b0d-772d2c955162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7e654-f3c1-45be-a379-d0f58d02974e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab0e23-9bcc-4aaa-969b-fe0a3b2d6b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011aded-de00-48c1-9645-eec12506c8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
