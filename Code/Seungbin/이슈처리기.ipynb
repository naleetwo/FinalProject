{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4b9c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 23.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "## 질병데이터 제거\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "target_dir = \"./data_for_yolo/data\"\n",
    "\n",
    "for tra_val in os.listdir(target_dir):\n",
    "    for img_lab in tqdm(os.listdir(os.path.join(target_dir, tra_val))):\n",
    "        folder_path = os.path.join(target_dir, tra_val, img_lab)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.startswith(\"V006\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7754e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.124 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.121  Python-3.9.13 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:\\Python\\work\\project\\data_for_yolo\\data.yaml, epochs=1, patience=15, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012018 parameters, 3012002 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce GTX 1060 6GB) 6.00G total, 0.10G reserved, 0.06G allocated, 5.84G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     3012018           0         0.264         67.35         105.5        (1, 3, 640, 640)                    list\n",
      "     3012018           0         0.371         34.01         80.02        (2, 3, 640, 640)                    list\n",
      "     3012018           0         0.673         40.67         104.2        (4, 3, 640, 640)                    list\n",
      "     3012018           0         1.248         56.18         121.9        (8, 3, 640, 640)                    list\n",
      "     3012018           0         2.523         85.85         246.4       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 25 for CUDA:0 4.02G/6.00G (67%) \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Python\\work\\project\\data_for_yolo\\data\\train\\labels... 38141 images, 166 backgrounds, 0 corrupt: 100\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Python\\work\\project\\data_for_yolo\\data\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Python\\work\\project\\data_for_yolo\\data\\valid\\labels... 11007 images, 0 backgrounds, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Python\\work\\project\\data_for_yolo\\data\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005859375000000001), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1      3.23G     0.9138      1.132     0.9924         43        640: 100%|██████████| 1533/1533 [21:48<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 221/221 [04:\n",
      "                   all      11007      31009      0.732      0.637      0.673      0.499\n",
      "\n",
      "1 epochs completed in 0.440 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.121  Python-3.9.13 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144MiB)\n",
      "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 221/221 [03:\n",
      "                   all      11007      31009      0.732      0.637      0.673      0.499\n",
      "                   bud      11007       8064      0.727      0.671      0.672      0.372\n",
      "                 fully      11007       1550      0.607      0.157      0.231      0.127\n",
      "                 green      11007      21002      0.887      0.876      0.934      0.784\n",
      "                 ripen      11007        393      0.709      0.842      0.852      0.713\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(data='D:\\\\Python\\\\work\\\\project\\\\data_for_yolo\\\\data.yaml', \n",
    "                      epochs=1,\n",
    "                     imgsz=640,\n",
    "                     batch=-1,\n",
    "                     device=0,\n",
    "                     patience=15,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5425b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 98476/98476 [35:10<00:00, 46.65file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    total_files = sum([len(files) for r, d, files in os.walk(path)])\n",
    "    \n",
    "    # Creating a progress bar\n",
    "    progress_bar = tqdm(total=total_files, unit=\"file\")\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "            progress_bar.update(1) # Updating the progress bar\n",
    "    \n",
    "    progress_bar.close()\n",
    "\n",
    "dir_path = 'D:\\\\Python\\\\work\\\\project\\\\data_for_yolo\\\\target' # specify directory\n",
    "zip_path = 'D:\\\\Python\\\\work\\\\project\\\\data_for_yolo\\\\target.zip' # specify the output zip file name\n",
    "\n",
    "zipf = zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir(dir_path, zipf)\n",
    "zipf.close()\n",
    "\n",
    "print(\"Zip file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d8d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 98475/98475 [40:32<00:00, 40.48file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file created successfully!\n"
     ]
    }
   ],
   "source": [
    "## 특정 폴더와 파일을 압축\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    total_files = sum([len(files) for r, d, files in os.walk(path)])\n",
    "    \n",
    "    # Creating a progress bar\n",
    "    progress_bar = tqdm(total=total_files, unit=\"file\")\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "            progress_bar.update(1) # Updating the progress bar\n",
    "    \n",
    "    progress_bar.close()\n",
    "\n",
    "def add_file_to_zip(path, ziph):\n",
    "    ziph.write(path, os.path.basename(path))\n",
    "\n",
    "dir_path = 'D:\\\\Python\\\\work\\\\project\\\\data_for_yolo\\\\data' # specify directory\n",
    "file_path = 'D:\\\\Python\\\\work\\\\project\\\\data_for_yolo\\\\data.yaml' # specify single file\n",
    "zip_path = 'D:\\\\Python\\\\work\\\\project\\\\data_for_yolo\\\\data.zip' # specify the output zip file name\n",
    "\n",
    "zipf = zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED)\n",
    "\n",
    "# Zip the directory\n",
    "zipdir(dir_path, zipf)\n",
    "\n",
    "# Add the single file\n",
    "add_file_to_zip(file_path, zipf)\n",
    "\n",
    "zipf.close()\n",
    "\n",
    "print(\"Zip file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "folder_path = \".\\\\data_for_yolo\\\\data\\\\train\\\\images\"\n",
    "labels_path = \".\\\\data_for_yolo\\\\data\\\\train\\\\labels\"\n",
    "\n",
    "def parse_yolo_coordinates(yolo_str):\n",
    "    parts = yolo_str.split()\n",
    "    return int(parts[0]), float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "\n",
    "def change_class_id(yolo_str, new_class_id):\n",
    "    parts = yolo_str.split()\n",
    "    parts[0] = str(new_class_id)\n",
    "    return ' '.join(parts)\n",
    "\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith('.png') and ('d1' in f or 'd2' in f)]\n",
    "\n",
    "resume_file = 'V001_tom1_43_085_d2_11_20211031_18_06072546_38102607.png'\n",
    "if resume_file in image_files:\n",
    "    idx = image_files.index(resume_file)\n",
    "    image_files = image_files[idx:]\n",
    "\n",
    "total_files = len(image_files)\n",
    "farm_counts = {f\"tom{i+1}\": len([f for f in image_files if f\"tom{i+1}\" in f]) for i in range(6)}\n",
    "\n",
    "for i, img_name in enumerate(image_files, start=1):\n",
    "    farm_name = img_name.split('_')[1]  # assuming 'tom1' always at this position\n",
    "\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    txt_path = os.path.join(labels_path, img_name.replace('.png', '.txt'))\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_width, img_height = 1080, 1920\n",
    "\n",
    "    with open(txt_path, 'r') as file:\n",
    "        yolo_strs = file.readlines()\n",
    "\n",
    "    for idx, yolo_str in enumerate(yolo_strs):\n",
    "        fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "        ax.imshow(image)\n",
    "\n",
    "        class_id, x, y, w, h = parse_yolo_coordinates(yolo_str)\n",
    "        x, y, w, h = x * img_width, y * img_height, w * img_width, h * img_height\n",
    "        bbox = patches.Rectangle((x - w / 2, y - h / 2), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "        ax.add_patch(bbox)\n",
    "\n",
    "        plt.pause(0.01)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Processing image {i} of {total_files}, farm {farm_name} ({image_files[:i-1].count(farm_name)} of {farm_counts[farm_name]})\")\n",
    "        \n",
    "        answer = input(f\"Do you want to change class id of object {idx} in image {img_name}? (y/n): \")\n",
    "        if answer.lower() == 'y':\n",
    "            yolo_strs[idx] = change_class_id(yolo_strs[idx], '1') + \"\\n\"\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    with open(txt_path, 'w') as file:\n",
    "        file.writelines(yolo_strs)\n",
    "\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
